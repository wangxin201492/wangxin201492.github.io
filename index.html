<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="my blogs">
<meta property="og:type" content="website">
<meta property="og:title" content="wangxin201492">
<meta property="og:url" content="https://wangxin201492.github.io/index.html">
<meta property="og:site_name" content="wangxin201492">
<meta property="og:description" content="my blogs">
<meta property="article:author" content="wangxin201492">
<meta name="twitter:card" content="summary">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"right","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://wangxin201492.github.io/"/>





  <title>wangxin201492</title>
  





  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?b4b40ab284f92e7b4921a8198acda5b7";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




<meta name="generator" content="Hexo 4.2.1"></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-right 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">wangxin201492</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://wangxin201492.github.io/MongoDB/sharding/splitChunk/MongoDB-sharding-troubleshoot-cacheRefreshX/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="wangxin201492">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="wangxin201492">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/MongoDB/sharding/splitChunk/MongoDB-sharding-troubleshoot-cacheRefreshX/" itemprop="url">MongoDB 路由表刷新导致响应慢</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-11-29T14:16:20+08:00">
                2020-11-29
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/MongoDB/" itemprop="url" rel="index">
                    <span itemprop="name">MongoDB</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/MongoDB/sharding/" itemprop="url" rel="index">
                    <span itemprop="name">sharding</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/MongoDB/sharding/splitChunk/" itemprop="url" rel="index">
                    <span itemprop="name">splitChunk</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>MongoDB sharding 实例从 <strong>3.4版本</strong> 升级到 <strong>4.0版本</strong> 以后插入性能明显降低，观察日志发现大量的 <code>insert</code> 请求慢日志：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2020-08-19T16:40:46.563+0800 I COMMAND [conn1528] command sdb.sColl command: insert &#123; insert: &quot;sColl&quot;, xxx&#125; ... locks: &#123;Global: &#123; acquireCount: &#123; r: 6, w: 2 &#125; &#125;, Database: &#123; acquireCount: &#123; r: 2, w: 2 &#125; &#125;, Collection: &#123; acquireCount: &#123; r: 2, w: 2 &#125;, acquireWaitCount: &#123; r: 1 &#125;, timeAcquiringMicros: &#123; r: 2709634 &#125; &#125; &#125; protocol:op_msg 2756ms</span><br></pre></td></tr></table></figure>

<p>日志中可以看到 <code>insert</code> 请求执行获取 collection 上的 IS锁 2次，其中一次发生等待，等待时间为2.7s，这与 <code>insert</code> 请求执行时间保持一致。说明性能降低与<strong>锁等待</strong>有明显的相关性。</p>
<p>追溯日志发现 2.7s 前，系统正在进行 collection 元数据刷新（2.7s的时长与collection本身chunk较多相关）：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">2020-08-19T16:40:43.853+0800 I SH_REFR [ConfigServerCatalogCacheLoader-20] Refresh for collection sdb.sColl from version 25550573|83||5f59e113f7f9b49e704c227f to version 25550574|264||5f59e113f7f9b49e704c227f took 8676ms</span><br><span class="line">2020-08-19T16:40:43.853+0800 I SHARDING [conn1527] Updating collection metadata for collection sdb.sColl from collection version: 25550573|83||5f59e113f7f9b49e704c227f, shard version: 25550573|72||5f59e113f7f9b49e704c227f to collection version: 25550574|264||5f59e113f7f9b49e704c227f, shard version: 25550574|248||5f59e113f7f9b49e704c227f</span><br></pre></td></tr></table></figure>



<h2 id="chunk-版本信息"><a href="#chunk-版本信息" class="headerlink" title="chunk 版本信息"></a>chunk 版本信息</h2><p>首先，我们来理解下上文中的版本信息。在上文日志中看到，shard version 和 collection version 形式均为 「25550573|83||5f59e113f7f9b49e704c227f」，这即是一个 chunk version，通过 “|” 和 “||” 将版本信息分为三段：</p>
<ul>
<li>第一段为 <code>major version</code> : 整数，用于<strong>辨识路由指向是否发生变化，以便各节点及时更新路由</strong>。比如在发生chunk 在 shard 之间迁移时会增加</li>
<li>第二段为 <code>minor version</code> : 整数，主要用于记录<strong>不影响路由指向的一些变化</strong>。比如chunk 发生 split 时增加</li>
<li>第三段为 <code>epoch</code> : objectID，标识集合的唯一实例，用于<strong>辨识集合是否发生了变化</strong>。只有当 collection 被 drop 或者 collection的shardKey发生refined时 会重新生成</li>
</ul>
<p><strong>shard version</strong> 为 sharded collection 在目标shard上最高的 chunk version</p>
<p><strong>collection version</strong> 为 sharded collection 在所有shard上最高的 chunk version</p>
<blockquote>
<p>下文 “路由更新触发场景” - “场景一：请求触发” 中就描述了使用 shard version 来触发路由更新的典型应用场景。</p>
</blockquote>
<h2 id="路由信息存储"><a href="#路由信息存储" class="headerlink" title="路由信息存储"></a>路由信息存储</h2><p>sharded collection 的路由信息被记录在 configServer 的 <a href="https://docs.mongodb.com/manual/reference/config-database/#config.chunks" target="_blank" rel="noopener">config.chunks</a> 集合中，而 mongos&amp;shardServer 则按需从 configServer 中加载到本地缓存(CatalogCache)中。</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// config.chunks</span></span><br><span class="line">&#123;</span><br><span class="line">        <span class="attr">"_id"</span> : <span class="string">"sdb.sColl-name_106.0"</span>,</span><br><span class="line">        "lastmod" : Timestamp(4, 2),</span><br><span class="line">        "lastmodEpoch" : ObjectId("5f3ce659e6957ccdd6a56364"),</span><br><span class="line">        "ns" : "sdb.sColl",</span><br><span class="line">        "min" : &#123;</span><br><span class="line">                "name" : 106</span><br><span class="line">        &#125;,</span><br><span class="line">        "max" : &#123;</span><br><span class="line">                "name" : 107</span><br><span class="line">        &#125;,</span><br><span class="line">        "shard" : "mongod8320",</span><br><span class="line">        "history" : [</span><br><span class="line">                &#123;</span><br><span class="line">                        "validAfter" : Timestamp(1598001590, 84),</span><br><span class="line">                        "shard" : "mongod8320"</span><br><span class="line">                &#125;</span><br><span class="line">        ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>上面示例中记录的 document 表示该 chunk ：</p>
<ul>
<li>所属的 namespace 为 “sdb.sColl”，其 epoch 为 “5f3ce659e6957ccdd6a56364”</li>
<li>chunk区间为 {“name”: 106} ~ {“name”: 107}，chunk版本为 {major=4, minor=2}，在 mongod8320 的shard上</li>
<li>同时记录了一些历史信息</li>
</ul>
<h2 id="路由更新触发场景"><a href="#路由更新触发场景" class="headerlink" title="路由更新触发场景"></a>路由更新触发场景</h2><p>路由更新采用 “lazy” 的机制，非必须的场景下不会进行路由更新。主要有2种场景会进行路由刷新：</p>
<h3 id="场景一：请求触发"><a href="#场景一：请求触发" class="headerlink" title="场景一：请求触发"></a>场景一：请求触发</h3><p>mongos 收到客户端请求后，根据当前 CatalogCache 缓存中的路由信息，为客户端请求增加一个 <strong>「shardVersion」</strong> 的元信息。然后按照路由信息将请求分发到目标shard上。</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#123; </span><br><span class="line">  insert: "sCollName", </span><br><span class="line">  documents: [ &#123; _id: ObjectId('5f685824c800cd1689ca3be8'), name: xxxx &#125; ], </span><br><span class="line">  shardVersion: [ Timestamp(5, 1), ObjectId('5f3ce659e6957ccdd6a56364') ], </span><br><span class="line">  $db: "sdb"</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>shardServer 收到 mongos 发来的请求后，提取其中的 <strong>「shardVersion」</strong> 字段，并与本地存储的 <strong>「shardVersion」</strong>进行比较。比较二者 <code>epoch &amp; majorVersion</code> 是否相同，相同则认为可以进行写入。如果版本不匹配，则抛出一个 <code>StaleConfigInfo</code> 异常。对于该异常，shardServer&amp;mongos 均会进行处理，逻辑基本一致：如果本地路由信息是低版本的，则进行路由刷新。</p>
<h3 id="场景二：特殊请求"><a href="#场景二：特殊请求" class="headerlink" title="场景二：特殊请求"></a>场景二：特殊请求</h3><ul>
<li>一些命令执行一定会触发路由信息变化，比如 <code>moveChunk</code></li>
<li>受其他节点行为影响，收到 <code>forceRoutingTableRefresh</code> 命令，强制刷新</li>
<li>一些行为必须要获取最新的路由信息，比如 <code>cleanupOrphaned</code></li>
</ul>
<h2 id="路由刷新行为"><a href="#路由刷新行为" class="headerlink" title="路由刷新行为"></a>路由刷新行为</h2><p><img src="MongoDB-cache-refresh.png" alt="MongoDB-cache-refresh"></p>
<p>具体的刷新行为分为两步：</p>
<p>第一步：从config节点拉取权威的路由信息，并进行CatalogCache路由信息刷新。实际最终是通过 <code>ConfigServerCatalogCacheLoader</code> 线程来进行的，构造一个</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">	<span class="attr">"ns"</span>: namespace,</span><br><span class="line">  "lastmod": &#123; $gte: sinceVersion&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>请求来获取路由信息。如果本地没有collection的路由信息，则会那么全量获取路由信息，<code>sinceVersion</code> = (0,0) ；否则只需增量获取路由信息， <code>sinceVersion</code> = 本地路由信息中最大的版本号，即 <strong>shard version</strong>。</p>
<p><code>ConfigServerCatalogCacheLoader</code> 获得到路由信息以后，会刷新 CatalogCache中的路由信息，此时系统日志会打印上文中看到的：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2020-08-19T16:40:43.853+0800 I SH_REFR [ConfigServerCatalogCacheLoader-20] Refresh for collection sdb.sColl from version 25550573|83||5f59e113f7f9b49e704c227f to version 25550574|264||5f59e113f7f9b49e704c227f took 8676ms</span><br></pre></td></tr></table></figure>



<p>第二步：更新 <code>MetadataManager</code>(用于维护集合的元信息，并提供对部分场景获取一个一致性的路由信息等功能) 中的 路由信息。更新 <code>MetadataManager</code> 时为了保证一致性，会给 collection 增加一个 <strong>X锁</strong>。更新过程中，系统日志会打印上文看到的第二条日志：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2020-08-19T16:40:43.853+0800 I SHARDING [conn1527] Updating collection metadata for collection sdb.sColl from collection version: 25550573|83||5f59e113f7f9b49e704c227f, shard version: 25550573|72||5f59e113f7f9b49e704c227f to collection version: 25550574|264||5f59e113f7f9b49e704c227f, shard version: 25550574|248||5f59e113f7f9b49e704c227f</span><br></pre></td></tr></table></figure>

<p><strong>这里也即是文章开篇提到影响我们性能的日志，根因还是由于更新元信息的X锁导致。</strong></p>
<h2 id="3-6-版本对-chunk-version-管理的变化"><a href="#3-6-版本对-chunk-version-管理的变化" class="headerlink" title="3.6+版本对 chunk version 管理的变化"></a>3.6+版本对 chunk version 管理的变化</h2><p>那么，为什么 3.4版本 没有问题，而到了 4.0版本 却发生了性能退化呢？这里直接给出答案：<strong>3.6&amp;4.0的最新小版本当中，当shard进行 splitChunk 时，如果 shardVersion == collectionVersion ，则会增加 major version，进而触发路由刷新。</strong>而3.4版本中只会增加 minor version。这里首先来看下 splitChunk 的基本流程，随后我们再来详述为什么要做这样的改动</p>
<h3 id="splitChunk-流程"><a href="#splitChunk-流程" class="headerlink" title="splitChunk 流程"></a>splitChunk 流程</h3><p><img src="MongoDB-splitChunk.png" alt="MongoDB-splitChunk"></p>
<ul>
<li><strong>「auto-spliting触发」</strong>：在 4.0及以前的版本中，sharding实例的 auto-spliting 是由 mongos 来触发的。每次有写入请求时，mongos都会记录对应chunk的写入量，并判断是否要向 shardServer 下发一次 <code>splitChunk</code> 请求。判断标准：<code>dataWrittenBytes &gt;= maxChunkSize / 5(固定值)</code>。</li>
<li><strong>「splitVector + splitChunk」</strong>：向 chunk所在的shard 下发一个 <code>splitVector</code> 请求，获取对该chunk进行拆分的拆分点。该过程会根据索引进行一定的数据扫描及计算，详见：<a href="https://developer.aliyun.com/article/119494" target="_blank" rel="noopener">SplitVector命令</a>。若 <code>splitVector</code> 获取到了具体的拆分点，则再次向 chunk所在的shard 下发一个 <code>splitChunk</code> 请求，进行实际的拆分。</li>
<li><strong>「_configsvrCommitChunkSplit」</strong>：shardServer 收到 <code>splitChunk</code> 请求后，首先获取一个分布式锁，然后向 configServer 下发一个 <code>_configsvrCommitChunkSplit</code>。configServer 收到该请求后进行数据更新，完成splitChunk，过程中会有 chunk 版本信息的变化。</li>
<li><strong>「route refresh」</strong>：上述流程正常完成后，mongos进行路由刷新。</li>
</ul>
<h3 id="splitChunk-时，chunk-version变化"><a href="#splitChunk-时，chunk-version变化" class="headerlink" title="splitChunk 时，chunk version变化"></a>splitChunk 时，chunk version变化</h3><p>在 <a href="https://jira.mongodb.org/browse/SERVER-41480" target="_blank" rel="noopener">SERVER-41480</a> 中，对splitChunk时，chunk version版本管理进行了调整</p>
<p>在3.4版本以及3.6、4.0较早的小版本中，<strong>「_configsvrCommitChunkSplit」</strong> 只会增加 chunk 的minor version。</p>
<blockquote>
<p>The original reasoning for this was to prevent unnecessary routing table refreshes on the routers, which don’t ordinarily need to know about chunk splits (since they don’t change targeting information).</p>
</blockquote>
<p>根本原因是为了保护 mongos 不做必须要的路由刷新，因为 splitChunk 并不会改变路由目标，所以 mongos 不需要感知。</p>
<p>但是只进行小版本的自增，如果用户进行单调递增的写入，容易造成较大的性能开销。</p>
<p><img src="MongoDB-SERVER-41480.png" alt="MongoDB-SERVER-41480"></p>
<p>假设 sharding实例有2个mongos：mongosA、mongosB，2个shard：shardA(chunkRange: MinKey ~ 0)，shardB(chunkRange: 0 ~ Maxkey)。用户持续单调递增写入。</p>
<ul>
<li><strong>T1时刻</strong>：mongosB首先判断chunk满足<strong>「auto-spliting触发」</strong> 条件，向 shardB 发送<strong>「splitVector + splitChunk」</strong>，在请求正常结束后，mongosB触发路由刷新。此时，shardB 的 chunkRange 为 0 ~ 100，100 ~ Maxkey。</li>
<li>随后在一定时间内（比如<strong>T2时刻</strong>），mongosB无法满足<strong>「auto-spliting触发」</strong> 条件，而mongosA持续判断满足条件，向shardB发送 <strong>「splitVector + splitChunk」</strong>，但最终在<strong>「_configsvrCommitChunkSplit」</strong>步骤，由于 mongosA 的路由表不是最新的，所以无法按照其请求将 0 ~ Maxkey 进行拆分，最终无法成功执行。由于整个流程没有完整结束，所以 mongosA 也无法进行 路由表更新，则<strong>在这段时间内持续会有这样的无效请求</strong>。</li>
</ul>
<p>而如上文描述的，<code>splitVector</code> 根据索引进行一定的数据扫描、计算，<code>splitChunk</code> 会获取分布式锁，均为耗时较高的请求，所以这种场景对性能的影响不可忽视。</p>
<p>在 <strong>SERVER-41480</strong>中对上述问题进行修复，修复的方式是如果 shardVersion == collectionVersion (即 collection上次的 chunk split 也发生在该shard上) ，则会增加 major version，以触发各节点路由的刷新。修复的版本为<code>3.6.15</code>, <code>4.0.13</code>, <code>4.3.1</code>, <code>4.2.2</code>。</p>
<p>而这个修复则导致了开篇我们遇到的问题，确切些来说，<strong>任何在 shardVersion == collectionVersion 的 shard 上进行 split 操作都会导致全局路由的刷新。</strong></p>
<h2 id="官方修复"><a href="#官方修复" class="headerlink" title="官方修复"></a>官方修复</h2><p><a href="https://jira.mongodb.org/browse/SERVER-49233" target="_blank" rel="noopener">SERVER-49233</a> 中对这个问题进行了详细的阐述：</p>
<blockquote>
<p>we chose a solution, which erred on the side of correctness, with the reasoning that on most systems auto-splits are happening rarely and are not happening at the same time across all shards.</p>
</blockquote>
<p>我们选择的方案，宁可过于注重正确性（<strong>SERVER-41480</strong>），理由是在大多数的系统中，auto-split很少发生，而且不会同时在所有shard上发生。</p>
<blockquote>
<p>However, this logic seems to be causing more harm than good in the case of almost uniform writes across all chunks. If it is the case that all shards are doing splits almost in unison, under this fix there will constantly be a bump in the collection version, which means constant stalls due to StaleShardVersion.</p>
</blockquote>
<p>然而，在对所有chunk进行均衡写入的情况下，这个逻辑似乎弊大于利。如果这种场景下，所有的shard同时进行split，那么在 <strong>SERVER-41480</strong> 修复下，collection version 将不断出现颠簸，也就意味着不断由于 <code>StaleShardVersion</code> 而导致不断暂停。</p>
<p><img src="MongoDB-SERVER-49233.png" alt="MongoDB-SERVER-49233"></p>
<p>举例来详细说明下这个问题：假设某sharding实例有4个shard，各持有2个chunk，当前时刻major version=N。客户端对sharding实例的所有chunk进行均衡的写入，某时刻mongosA判断所有chunk符合split条件，依次对各shard进行连续的 split chunk 触发。为了便于说明，假设如图所示，在T1，T2，T3，T4时刻，依次在ShardA、shardB、shardC、shardD进行连续的chunk split触发，那么：</p>
<ul>
<li>T1.1时刻 chunk1 发生 split，使得 shardA 的 shardVersion == collection；T1.2时刻 chunk2 发生 split，触发 configServer major version ++ ，此时最新的major version=N+1；随后的T1.3时刻，shardA感知后刷新本地major version=N+1</li>
<li>随后的T2、T3、T4时刻依次发生上述流程。</li>
<li>最终在T5时刻，mongosA 在触发完split chunk后主动刷新路由表，感知major version = N+4</li>
</ul>
<p>那么当系统中另外一个mongos（未发生更新，路由表中major version=N）向shard（比如shardB）发送请求时</p>
<ul>
<li>在第一次请求交互后，mongosX感知自身major version落后，与configServer交互，更新本地路由表后下发第二次请求</li>
<li>第二次请求中，shardB感知自身major version落后，通过configServer拉取并更新路由表</li>
<li>在第三次请求中，双方均获得最新的路由表，而完成此次请求</li>
<li>mongos&amp;shard之间感知路由表落后靠请求交互时的 <code>StaleShardVersion</code> 来完成，而路由表更新的过程中，所有需要依赖该集合路由表完成的请求，都需要<strong>等待路由表更新完成</strong>后才能继续。所以上述过程即jira中描述的：<strong>不断由于</strong> <strong><code>StaleShardVersion</code></strong> <strong>而导致不断暂停。</strong></li>
</ul>
<p>同时 <strong>SERVER-49233</strong> 提供了具体的解决方案，在 <code>3.6.19</code>、<code>4.0.20</code>、<code>4.2.9</code> 及后续的版本中，提供 <code>incrementChunkMajorVersionOnChunkSplit</code> 参数， 默认为 false（即 <code>splitChunk</code> 不会增加major version），可在配置文件或者通过启动setParameter的方式设置为true。</p>
<p>而由于 auto-spliting 逻辑在 4.2版本 修改为在 shardServer 上触发(<a href="https://jira.mongodb.org/browse/SERVER-34448" target="_blank" rel="noopener">SERVER-34448</a>)， 也就不会再有 mongos 频繁下发无效 splitChunk 的场景。 所以对于 4.4 版本， <a href="https://jira.mongodb.org/browse/SERVER-49433" target="_blank" rel="noopener">SERVER-49433</a> 直接将增加 major version 的逻辑回滚掉，只会增加 minor version。（4.2版本由于中间版本提供了 major version 逻辑，所以提供 <code>incrementChunkMajorVersionOnChunkSplit</code> 来让用户选择）</p>
<p>这里对各版本行为总结如下：</p>
<ul>
<li>只会增加 minor version：<code>3.4</code>所有版本、<code>3.6.15</code> 之前的版本、<code>4.0.13</code>之前的版本、<code>4.2.2</code>之前的版本、<code>4.4</code>（暂未发布）</li>
<li>shardVersion == collectionVersion 会增加 major version，否则增加minor version：<code>3.6.15</code>~ <code>3.6.18</code>（包含）之间的版本、<code>4.0.13</code> ~ <code>4.0.19</code>（包含）之间的版本、<code>4.2.2</code> ~ <code>4.2.8</code>（包含）之间的版本</li>
<li>提供 <code>incrementChunkMajorVersionOnChunkSplit</code> 参数，默认只增加 minor version：<code>3.6.19</code>及后续版本、<code>4.0.20</code>及后续版本、<code>4.2.9</code>及后续版本</li>
</ul>
<h2 id="使用场景与解决方案"><a href="#使用场景与解决方案" class="headerlink" title="使用场景与解决方案"></a>使用场景与解决方案</h2><table>
<thead>
<tr>
<th>MongoDB版本</th>
<th>使用场景</th>
<th>修复方案</th>
</tr>
</thead>
<tbody><tr>
<td>4.2以下</td>
<td>数据写入固定在某些Shard</td>
<td>采用可以增加major version的版本（或设置 <code>incrementChunkMajorVersionOnChunkSplit</code> = true）</td>
</tr>
<tr>
<td>4.2以下</td>
<td>数据在shard之间写入较均衡</td>
<td>采用仅增加minor version的版本（或设置 <code>incrementChunkMajorVersionOnChunkSplit</code> = false）</td>
</tr>
<tr>
<td>4.2</td>
<td>数据写入固定在某些Shard</td>
<td>由于4.2版本 splitChunk 在shardServer上触发，所以无需关心</td>
</tr>
<tr>
<td>4.2</td>
<td>数据在shard之间写入较均衡</td>
<td>采用仅增加minor version的版本（或设置 <code>incrementChunkMajorVersionOnChunkSplit</code> = false）</td>
</tr>
</tbody></table>
<p><a href="https://www.aliyun.com/product/mongodb" target="_blank" rel="noopener">阿里云MongoDB</a> 4.2版本中已经跟进了官方修复。遇到该问题的用户可以将实例升级到4.2的最新小版本，而后按需配置<code>incrementChunkMajorVersionOnChunkSplit</code>即可。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://wangxin201492.github.io/lock/OCC/OCC-overview/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="wangxin201492">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="wangxin201492">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/lock/OCC/OCC-overview/" itemprop="url">关于乐观锁的探索</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-06-16T16:41:56+08:00">
                2020-06-16
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/lock/" itemprop="url" rel="index">
                    <span itemprop="name">lock</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/lock/OCC/" itemprop="url" rel="index">
                    <span itemprop="name">OCC</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<p><strong>乐观并发控制</strong>（又名“<strong>乐观锁</strong>”，Optimistic Concurrency Control，缩写“OCC”）</p>
</blockquote>
<h2 id="为什么要使用锁"><a href="#为什么要使用锁" class="headerlink" title="为什么要使用锁"></a>为什么要使用锁</h2><p>在多线程编程领域，基本上所有的编程模型都采用了“<strong>并发访问串行处理</strong>”的策略，而方法就是给临界资源加一把锁</p>
<h2 id="并发控制策略-：乐观锁、悲观锁"><a href="#并发控制策略-：乐观锁、悲观锁" class="headerlink" title="并发控制策略 ：乐观锁、悲观锁"></a>并发控制策略 ：乐观锁、悲观锁</h2><p>锁的一种宏观分类方式是<strong>悲观锁</strong>和<strong>乐观锁</strong>。悲观锁与乐观锁<strong>并不是特指某个锁</strong>，而是在并发情况下的两种不同策略。</p>
<ul>
<li>悲观锁(Pessimistic Lock) : 就是很悲观，每次去拿数据的时候都认为别人会修改。所以<strong>每次在拿数据的时候都会上锁</strong>。这样别人想拿数据就被挡住，直到悲观锁被释放。</li>
<li>乐观锁(Optimistic Lock) : 就是很乐观，每次去拿数据的时候都认为别人不会修改。所以不会上锁，<strong>更新前检查在读取至更新这段时间别人有没有修改过这个数据</strong>。如果修改过，则重新读取，再次尝试更新，循环上述步骤直到更新成功（当然也允许更新失败的线程放弃操作）。</li>
</ul>
<p>缺点：悲观锁阻塞事务，乐观锁回滚重试。</p>
<h3 id="悲观锁的代价"><a href="#悲观锁的代价" class="headerlink" title="悲观锁的代价"></a>悲观锁的代价</h3><p>日常用到的加锁基本都是悲观锁。悲观锁是用来做并发最简单的方式，其代价也是最高的：</p>
<ul>
<li>加锁、释放锁会需要操作系统进行上下文切换和调度延时，在上下文切换的时候，cpu之前缓存的指令和数据都将失效，这个过程将增加系统开销。</li>
<li>多个线程同时竞争锁，锁竞争机制本身需要消耗系统资源。没有获取到锁的线程会被挂起直至获取锁，在线程被挂起和恢复执行的过程中也存在很大开销。</li>
<li>等待锁的线程会阻塞，影响实际的使用体验。如果被阻塞的线程优先级高，而持有锁的线程优先级低，将会导致优先级反转(Priority Inversion)。</li>
</ul>
<h3 id="乐观锁、悲观锁的选择"><a href="#乐观锁、悲观锁的选择" class="headerlink" title="乐观锁、悲观锁的选择"></a>乐观锁、悲观锁的选择</h3><p>适用场景考虑几个因素：</p>
<ol>
<li>响应速度：需要响应速度快使用乐观锁</li>
<li>冲突频率：<ol>
<li>对于资源竞争较少（多读场景、线程冲突较轻）的情况选择<strong>乐观锁</strong> ：使用悲观锁进行线程阻塞和唤醒切换以及用户态内核态间的切换操作额外浪费消耗cpu资源；而乐观锁操作自旋几率较少，因此可以获得更高的性能。</li>
<li>对于资源竞争严重（多写场景，线程冲突严重）的场景选择<strong>悲观锁</strong> ：乐观锁自旋的概率会比较大，从而浪费更多的CPU资源，效率低于悲观锁。</li>
</ol>
</li>
<li>重试代价：代价高则用悲观锁</li>
</ol>
<h2 id="乐观锁实现"><a href="#乐观锁实现" class="headerlink" title="乐观锁实现"></a>乐观锁实现</h2><p>乐观锁允许多个线程同时读取（因为根本没有加锁操作），但是只有一个线程可以成功更新数据，并导致其他要更新数据的线程回滚重试。因为整个过程中并没有“加锁”和“解锁”操作，因此乐观锁策略也被称为<strong>无锁编程</strong>。</p>
<p>换句话说，乐观锁其实不是“锁”，它仅仅是一个循环重试CAS的算法而已！（下文描述的版本号机制也是基于 MySQL 中提供了一个原子操作，这个原子操作最终也可能是一个CAS或者悲观锁）</p>
<h3 id="CAS"><a href="#CAS" class="headerlink" title="CAS"></a>CAS</h3><p>即<strong>compare and swap（比较与交换）</strong>，是一种有名的<strong>无锁算法</strong>。无锁编程，即不使用锁的情况下实现多线程之间的变量同步，也就是在没有线程被阻塞的情况下实现变量的同步，所以也叫非阻塞同步（Non-blocking Synchronization）。</p>
<p><strong>CAS算法</strong>涉及到三个操作数</p>
<ul>
<li>需要读写的内存值 V</li>
<li>进行比较的值 A</li>
<li>拟写入的新值 B</li>
</ul>
<p>当且仅当 V 的值等于 A时，CAS通过原子方式用新值B来更新V的值，否则不会执行任何操作（比较和替换是一个原子操作）。一般情况下是一个<strong>自旋操作</strong>，即<strong>不断的重试</strong>。</p>
<p><strong>CAS利用CPU指令，从硬件层面保证了操作的原子性，以达到类似于锁的效果。</strong></p>
<h4 id="CAS-带来的问题"><a href="#CAS-带来的问题" class="headerlink" title="CAS 带来的问题"></a>CAS 带来的问题</h4><ol>
<li><code>ABA</code>问题：比如说一个线程<code>T1</code>从内存位置<code>V</code>中取出<code>A</code>，这时候另一个线程<code>T2</code>也从内存中取出<code>A</code>，并且<code>T2</code>进行了一些操作变成了<code>B</code>，然后<code>T2</code>又将<code>V</code>位置的数据变成<code>A</code>，这时候线程<code>T1</code>进行<code>CAS</code>操作发现内存中仍然是<code>A</code>，然后<code>T1</code>操作成功。尽管线程<code>T1</code>的<code>CAS</code>操作成功，但可能存在潜藏的问题。</li>
<li>循环时间长开销大：自旋<code>CAS</code>（不成功，就一直循环执行，直到成功）如果长时间不成功，会给CPU带来非常大的执行开销。</li>
<li>只能保证一个共享变量的原子操作：当对一个共享变量执行操作时，我们可以使用循环CAS的方式来保证原子操作，但是对多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时候就可以用锁，或者有一个取巧的办法，就是把多个共享变量合并成一个共享变量来操作。</li>
</ol>
<h3 id="版本号机制"><a href="#版本号机制" class="headerlink" title="版本号机制"></a>版本号机制</h3><p>一般是在数据表中加上一个数据版本号version字段，表示数据被修改的次数，当数据被修改时，version值会加一。当线程A要更新数据值时，在读取数据的同时也会读取version值，在提交更新时，若刚才读取到的version值为当前数据库中的version值相等时才更新，否则重试更新操作，直到更新成功。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">update table set name &#x3D; &#39;XXX&#39;, version &#x3D; version + 1 where id &#x3D; #&#123;id&#125; and version &#x3D; #&#123;version&#125;;</span><br></pre></td></tr></table></figure>



<h3 id="MVCC-：-Multi-Version-Concurrency-Control-即多版本并发控制"><a href="#MVCC-：-Multi-Version-Concurrency-Control-即多版本并发控制" class="headerlink" title="MVCC ： Multi-Version Concurrency Control, 即多版本并发控制"></a>MVCC ： Multi-Version Concurrency Control, 即<strong>多版本并发控制</strong></h3><p>MVCC 是实现乐观锁的一种方案，用空间（多版本）以及回滚成本（冲突），保证可重复读且没有幻读（读小于自己事务ID的版本）避免（或减少）加锁。</p>
<h4 id="整体思路"><a href="#整体思路" class="headerlink" title="整体思路"></a>整体思路</h4><ol>
<li><strong>多版本并发控制</strong>（MVCC），来实现 MySQL 上的<code>多事务``并发访问</code>时，隔离级别控制；</li>
<li><strong>数据版本</strong>：并发事务执行时，同一行数据有多个版本</li>
<li><strong>事务版本</strong>：每个事务都有一个事务版本</li>
<li>版本有序 ：版本是通过<code>时间</code>来标识的<ul>
<li><strong>数据版本</strong>：包含<code>创建版本</code>（创建时间）、<code>删除版本</code>（删除时间）</li>
<li><strong>事务版本</strong>：事务的<code>创建时间</code>，作为<code>事务版本</code></li>
<li>Note：<strong>数据版本</strong>，并不包含<code>更新版本</code>（更新时间），因为，在多事务并发情况下，更新操作，实际是：<code>删除原数据</code> + <code>新增新数据</code></li>
</ul>
</li>
</ol>
<p><img src="https://wangxin201492.github.io/techImages/mvcc-version-relation.png" alt="mvcc-version-relation.png"></p>
<h4 id="MVCC-本质"><a href="#MVCC-本质" class="headerlink" title="MVCC 本质"></a>MVCC 本质</h4><ol>
<li>本质使用了<code>copy-on-write</code>（写时复制），为每个数据保留多份 snapshot</li>
<li>不同 snapshot 之间，使用<code>指针</code>连接成<code>链表</code>；</li>
<li>创建事务，能看到的 snapshot 是受限的，是链表上，<code>小于等于</code>当前事务版本的<code>最大版本</code>（读取已提交：离当前事务<code>最近</code>的<code>已提交</code>版本）</li>
<li><code>update</code> 操作，创建一个新的 snapshot，并使用事务版本，作为创建版本；</li>
</ol>
<p><img src="https://wangxin201492.github.io/techImages/mvcc-snapshot-list.png" alt="mvcc-snapshot-list.png"></p>
<h4 id="MVCC-历史数据清理"><a href="#MVCC-历史数据清理" class="headerlink" title="MVCC 历史数据清理"></a>MVCC 历史数据清理</h4><p>// TODO</p>
<h4 id="MVCC在事务中使用"><a href="#MVCC在事务中使用" class="headerlink" title="MVCC在事务中使用"></a>MVCC在事务中使用</h4><p>MVCC手段只适用于Msyql隔离级别中的读已提交（Read committed）和可重复读（Repeatable Read）</p>
<ol>
<li>Read uncimmitted由于存在脏读，即能读到未提交事务的数据行，所以不适用MVCC。原因是MVCC的创建版本和删除版本只要在事务提交后才会产生。</li>
<li>串行化由于是会对所涉及到的表加锁，并非行锁，自然也就不存在行的版本控制问题。</li>
</ol>
<p>通过以上总结，可知，MVCC主要作用于事务性的，有行锁控制的数据库模型。</p>
<p>RR 和 RC 隔离级别生成 ReadView 时间不同</p>
<ol>
<li>在 <code>RR</code> 隔离级别下，每个事务 <code>touch first read</code> 时（本质上就是执行第一个 <code>SELECT</code> 语句时，后续所有的 <code>SELECT</code> 都是复用这个 <code>ReadView</code> ，其它 <code>update</code> , <code>delete</code> , <code>insert</code> 语句和一致性读 <code>snapshot</code> 的建立没有关系），会将当前系统中的所有的活跃事务拷贝到一个列表生成 <code>ReadView</code> 。</li>
<li>在 <code>RC</code> 隔离级别下，每个 <code>SELECT</code> 语句开始时，都会重新将当前系统中的所有的活跃事务拷贝到一个列表生成 <code>ReadView</code> 。</li>
</ol>
<p>二者的区别就在于生成 <code>ReadView</code> 的时间点不同，一个是事务之后第一个 <code>SELECT</code> 语句开始、一个是事务中每条 <code>SELECT</code> 语句开始。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li><a href="https://zhuanlan.zhihu.com/p/71156910" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/71156910</a></li>
<li><a href="https://segmentfault.com/a/1190000016611415" target="_blank" rel="noopener">https://segmentfault.com/a/1190000016611415</a></li>
<li><a href="https://juejin.im/post/5b4977ae5188251b146b2fc8" target="_blank" rel="noopener">https://juejin.im/post/5b4977ae5188251b146b2fc8</a></li>
<li><a href="https://segmentfault.com/a/1190000015239603" target="_blank" rel="noopener">https://segmentfault.com/a/1190000015239603</a></li>
<li><a href="http://ningg.top/inside-mysql-transaction-and-mvcc/" target="_blank" rel="noopener">http://ningg.top/inside-mysql-transaction-and-mvcc/</a></li>
<li><a href="https://www.codercto.com/a/88775.html" target="_blank" rel="noopener">https://www.codercto.com/a/88775.html</a></li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://wangxin201492.github.io/MongoDB/MongoDB-Timer/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="wangxin201492">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="wangxin201492">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/MongoDB/MongoDB-Timer/" itemprop="url">MongoDB 源码中定时器机制</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-05-06T09:42:24+08:00">
                2020-05-06
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/MongoDB/" itemprop="url" rel="index">
                    <span itemprop="name">MongoDB</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>MongoDB 提供了2种定时执行机制</p>
<ul>
<li><code>TaskExecutor::scheduleWorkAt(Date_t when, CallbackFn&amp;&amp; work)</code></li>
<li><code>PeriodicRunner::PeriodicJob</code></li>
</ul>
<h2 id="TaskExecutor-scheduleWorkAt"><a href="#TaskExecutor-scheduleWorkAt" class="headerlink" title="TaskExecutor::scheduleWorkAt"></a>TaskExecutor::scheduleWorkAt</h2><p><code>TaskExecutor::scheduleWorkAt</code> 提供了一个在指定时间 <code>when</code> 执行的方式，具体在 <code>ThreadPoolTaskExecutor</code> 中实现。</p>
<p><code>ThreadPoolTaskExecutor</code>实现 <code>scheduleWorkAt</code> 方法和 <code>scheduleWork</code> 逻辑基本一致：将 <code>CallbackFn</code> 添加到一个 <code>WorkQueue</code> 中，并获得一个 <code>CallbackHandle</code>，随后将 <code>WorkQueue</code> 插入到 <code>_poolInProgressQueue</code> 中等待被处理。区别在于：</p>
<ul>
<li><code>scheduleWork</code> 将 <code>CallbackFn</code> 添加到一个 temp 的 WorkQueue，而 <code>scheduleWorkAt</code> 添加到 <code>_sleepersQueue</code></li>
<li><code>scheduleWork</code> 中直接将 <code>WorkQueue</code> 中数据插入到 <code>_poolInProgressQueue</code> 中，而 <code>scheduleWorkAt</code> 则是通过 <code>_net::setAlarm</code> 注册一个时间 when 后回调插入的(<code>_net</code> 为一个 <code>NetworkInterfaceTL</code> 成员)。</li>
</ul>
 <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">StatusWith&lt;TaskExecutor::CallbackHandle&gt; <span class="title">ThreadPoolTaskExecutor::scheduleWorkAt</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">                                         Date_t when, CallbackFn&amp;&amp; work)</span> </span>&#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">auto</span> wq = makeSingletonWorkQueue(<span class="built_in">std</span>::<span class="built_in">move</span>(work), <span class="literal">nullptr</span>, when);</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">auto</span> cbHandle = enqueueCallbackState_inlock(&amp;_sleepersQueue, &amp;wq);</span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">    <span class="keyword">auto</span> status = _net-&gt;setAlarm(cbHandle.getValue(), </span><br><span class="line">                                 when, </span><br><span class="line">                                 [<span class="keyword">this</span>, cbHandle = cbHandle.getValue()](Status status) &#123;</span><br><span class="line">            ...</span><br><span class="line">            scheduleIntoPool_inlock(&amp;_sleepersQueue, cbState-&gt;iter, <span class="built_in">std</span>::<span class="built_in">move</span>(lk));</span><br><span class="line">        &#125;);</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">return</span> cbHandle;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<blockquote>
<p> <strong>Note:</strong>   <code>scheduleWorkAt</code> 和 <code>scheduleWork</code> 都会返回一个 <code>TaskExecutor::CallbackHandle</code> 对象  <code>cbHandle</code>，这个 <code>cbHandle</code> <em>不是一个回调函数*，应该是表示回调状态 的一个对象， <code>CallbackHandle</code> 持有一个 <code>CallbackState</code> , 而 <code>CallbackState</code> 的类注释为 *”Class representing a  scheduled callback and providing methods for interacting with it.”</em></p>
<p>具体的回调函数即上文提到的 <code>CallbackFn</code> 被添加到 <code>WorkQueue</code>  中，而后被添加到*   <code>_poolInProgressQueue</code> 等待被消费</p>
</blockquote>
<p><code>NetworkInterfaceTL::setAlarm</code> 接收 3 个入参：<code>cbHandle</code>, <code>when</code>, <code>action</code>，<code>cbHandle</code> 主要做一些 状态管理 、 合理性校验等逻辑。action即为当面提到的将 <code>WorkQueue</code> 添加到 <code>_poolInProgressQueue</code> 的回调。</p>
<p><code>NetworkInterfaceTL::setAlarm</code> 中 构造了一个 <code>PromiseFuture</code> 对象 <strong>pf ( future为 action）</strong>，并将时间点 when，回调状态 <code>cbHandle</code>，新建一个 <code>ASIOReactorTimer timer</code>，以及 pf.promise 封装成一个 <code>AlarmState</code> 。然后调用 <code>timer-&gt;waitUntil( when )</code> 等待到达指定时间（witerUntil 实际上也是返回一个 Future），指定时间到达时调用 <code>_answerAlarm</code> 标记 满足 promise（及触发上文 action ）</p>
<p> 关于指定时间执行的行为则在 <code>NetworkInterfaceTL::setAlarm</code> 中实现。</p>
<p><code>ASIOReactorTimer</code> 中会持有一个 <code>_timer (asio::system_timer)</code> ，<code>waitUntil()</code> 中会依次调用 <code>_timer-&gt;expires_at()</code>, <code>_timer-&gt;async_wait()</code>进行计时等待</p>
<p><strong>总结一下</strong>：<code>TaskExecutor::scheduleWorkAt</code> 实际上是基于 <code>asio::system_timer</code> 库实现的指定时间执行逻辑。</p>
<ul>
<li>指定时间到达后，会标记 满足 promise ，调用 <code>_answerAlarm</code> </li>
<li><code>_answerAlarm</code> 中进行一系列判断后 也会标记 满足 promise ， 调用 action</li>
<li>action 中 会将 <code>_sleepersQueue</code> 中的数据插入到 <code>_poolInProgressQueue</code> 排队等待执行</li>
</ul>
<p>由于 整个逻辑中回调函数比较多，所以堆栈会比较冗长，这里是以 为例的堆栈：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#0  mongo::ReplicaSetMonitor::_doScheduledRefresh (this&#x3D;0x7f0362e0fb00, currentHandle&#x3D;...) at src&#x2F;mongo&#x2F;client&#x2F;replica_set_monitor.cpp:249</span><br><span class="line">#5  0x00007f035e3fdd28 in mongo::executor::ThreadPoolTaskExecutor::runCallback (this&#x3D;0x7f0362e19140, cbStateArg&#x3D;...) at src&#x2F;mongo&#x2F;executor&#x2F;thread_pool_task_executor.cpp:659</span><br><span class="line">#7  0x00007f035e3ff7ad in mongo::executor::ThreadPoolTaskExecutor::scheduleIntoPool_inlock(mongo::executor::ThreadPoolTaskExecutor::WorkQueue*, const iterator&amp;, const iterator&amp;, std::unique_lock&lt;std::mutex&gt;)</span><br><span class="line">#16 0x00007f035e3fee44 in mongo::executor::ThreadPoolTaskExecutor::scheduleWorkAt(mongo::Date_t, mongo::executor::TaskExecutor::CallbackFn&amp;&amp;)</span><br><span class="line">#30 0x00007f035e43d6f2 in mongo::executor::NetworkInterfaceTL::_answerAlarm(mongo::Status, std::shared_ptr&lt;mongo::executor::NetworkInterfaceTL::AlarmState&gt;)</span><br></pre></td></tr></table></figure>



<h2 id="PeriodicRunner-PeriodicJob"><a href="#PeriodicRunner-PeriodicJob" class="headerlink" title="PeriodicRunner::PeriodicJob"></a>PeriodicRunner::PeriodicJob</h2><p> Periodic* 类涉及3个接口：</p>
<ul>
<li><code>PeriodicJob</code> 描述一个周期性 job，接收3个参数：<strong>job名称 name, Job执行逻辑 callable, 执行间隔 period</strong></li>
<li><code>ControllableJob : PeriodicJob</code> 实际执行逻辑，<em>start / pause / resume / stop</em> .      <ul>
<li><code>PeriodicJobImpl</code> 继承实现了该类。</li>
</ul>
</li>
<li><code>PeriodicJobAnchor</code> : 包装一个 <code>ControllableJob</code> ，用于控制 <code>ControllableJob</code> 的执行。<em>start / pause /     resume / stop</em> .</li>
<li><code>PeriodicRunner</code> ： 提供一个<code>makeJob</code> – 初始化 <code>PeriodicJob</code> / <code>PeriodicJobImpl</code> / <code>PeriodicJobAnchor</code>.<ul>
<li><code>PeriodicRunnerImpl</code> 继承实现了该类</li>
</ul>
</li>
</ul>
<p>上面这几个接口主要提供 job 的描述，job 运行的管理，但是也有2个比较奇怪的地方：</p>
<ul>
<li><code>PeriodicJobImpl</code> 看名称疑似 <code>PeriodicJob</code> 的具体实现，然而却是 <code>ControllableJob</code> 的实现</li>
<li><code>PeriodicJobAnchor</code> 和 <code>ControllableJob</code> 都提供了 job 的 <em>start / pause / resume / stop</em> 行为。<code>PeriodicJobAnchor</code> 中包装一个 <code>ControllableJob</code> 对象 _handle，所有的 job 行为也都直接调用了 _handle 对应的函数</li>
</ul>
<p>每个 job 有独立的线程处理，线程的名称即为 job 的名称。job 的运行管理在 <code>PeriodicJobImpl::_run</code> 中实现，负责管理的 <em>pause / resume / stop</em> 等行为会修改 job 的执行状态，<code>_run</code> 在执行前根据被标记的执行状态作出具体的处理。</p>
<p>正常情况下( RUNNING状态 )，_run 会调用 <code>clockSource-&gt;waitForConditionUntil</code>  ( _clockSource 为 <code>servicecontext -&gt;getPreciseClockSource()</code> )，这中间由于 <code>tracksSystemClock = true / waitable = null</code>，所以时间等待最终的实现是 <code>stdx::condition_variable.wait_util(lock, deadline);</code></p>
<blockquote>
<p><strong>Note:</strong>   PeriodicRunner::PeriodicJob 虽然进行初始化的时候传入的是一个 interval ，但是实际最终执行还是基于上次  job 开始执行的时间 + interval 获得一个 deadline 来定义下一次任务的触发时</p>
</blockquote>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://wangxin201492.github.io/MongoDB/MongoDB-ReplicaSetMonitor/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="wangxin201492">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="wangxin201492">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/MongoDB/MongoDB-ReplicaSetMonitor/" itemprop="url">MongoDB ReplicaSetMonitor对shard探测机制</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-04-27T12:59:24+08:00">
                2020-04-27
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/MongoDB/" itemprop="url" rel="index">
                    <span itemprop="name">MongoDB</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>sharding实例对后端 shard 会进行状态探测，以发现 shard 是否有节点更新（ 选主、节点加入、节点异常）。提供探测能力的核心类为 <code>ReplicaSetMonitor</code> 及相关类。</p>
<p>对于状态探测的基本逻辑应该也比较好构思：<strong>定期状态探测、探测结果存储、探测结果查询</strong>。MongoDB中也按照这个逻辑来完成的： </p>
<ul>
<li><p><code>ReplicaSetMonitor</code> 提供状态查询的接口，以及定期探测触发能力。状态信息存储在 <code>_state</code> (<code>SetState</code>类型成员变量) 中</p>
</li>
<li><p><code>SetState</code> 存储 ReplicaSet shard 的状态信息。包装 Node 记录各个 Node 的信息，持有一个 <code>ScanState</code> 记录该 ReplicaSet 当前正在 scan 的信息</p>
</li>
<li><p>Refresher 进行实际的状态探测，提供一个 static 方法 <code>ensureScanInProgress</code> 来初始化一个 Refresher 进行探测。</p>
<ul>
<li><code>Refresher</code> 与 <code>SetState</code> 是一一绑定的，只有 <code>SetState</code> 在被探测状态，才会有对应的 <code>Refresher</code> 产生</li>
</ul>
</li>
<li><p><code>ScanState</code> 记录 <code>Refresher</code> 探测过程中的状态信息。<code>ScanState</code> 会被 <code>SetState::currentScan</code> 及 <code>Refresher::_scan</code> 持有，一般情况下这2个 scan 是相同的，但是可能存在并发的场景导致指向的不是同一个 scan， 这时候以 <code>SetState::currentScan</code> 为准。</p>
</li>
</ul>
<p>ReplicaSetMonitor / SetState / Refresher / ScanState 具体关系参考下图：</p>
<p><img src="https://wangxin201492.github.io/techImages/MongoDB-ReplicaSetMonitor.png" alt="MongoDB-ReplicaSetMonitor.png"></p>
<h2 id="探测目标-shard-要求"><a href="#探测目标-shard-要求" class="headerlink" title="探测目标 shard 要求"></a>探测目标 shard 要求</h2><p><strong>只有以 ReplicaSet 方式启动的 shard(包含 config )，才会持有一个 <code>ReplicaSetMonitor</code> 类的成员。</strong>即只有 ReplicaSet shard 才会被探测，以 Standalong 方式启动的 shard 不会进行探测</p>
<h2 id="探测触发"><a href="#探测触发" class="headerlink" title="探测触发"></a>探测触发</h2><p>ReplicaSetMonitor 中会<strong>定期进行 shard 状态探测</strong>，如果当前维系的状态<strong>不能满足其他代码的 ReadPreference 要求，也会下发探测</strong></p>
<h3 id="定期探测"><a href="#定期探测" class="headerlink" title="定期探测"></a>定期探测</h3><p><code>ReplicaSetMonitor</code> 初始化时会调用<code>_scheduleRefresh</code>，而后通过 <code>_scheduleRefresh</code> 和 <code>_doScheduledRefresh</code> 两个函数相互调用及 <code>TaskExecutor::scheduleWorkAt</code> 完成:</p>
<ul>
<li><code>_scheduleRefresh</code>中通过使用 <code>TaskExecutor::scheduleWorkAt</code> 注册定时任务，定时任务负责调用 <code>_doScheduledRefresh</code></li>
<li><code>_doScheduledRefresh</code> 负责调用 <code>Refresher::ensureScanInProgress</code> 进行 <code>Refresher</code> 新建与 探测下发。同时根据当前 <code>SetState</code> 的状态来决定下次刷新的周期，然后调用 <code>_scheduleRefresh</code> 注册新的定时任务</li>
</ul>
<p>默认情况下，定时任务每隔 <strong>kDefaultRefreshPeriod (30s)</strong> 执行一次。但是如果 SetState 的 waiters 结构中非空，则会将周期调整为 <strong>kExpeditedRefreshPeriod (500ms)</strong> 。SetState 的 waiters 结构中 数据添加在下文按需探测时，数据清理在探测执行完成时。</p>
<h3 id="按需探测"><a href="#按需探测" class="headerlink" title="按需探测"></a>按需探测</h3><p>代码中需要按照某种 ReadPreference 获得 shard 的部分节点地址时，会调用 ReplicaSetMonitor 提供 <code>getHostsOrRefresh</code> 函数。如果当前持有的 shard 信息不能满足 ReadPreference 时，会构造一个 promise-future，返回 future ，然后将 promise 添加到 SetState 的 waiter 中，并立即下发刷新。</p>
<ul>
<li>如果刷新结果能满足 ReadPreference ，则返回对应的host</li>
<li>如果不能满足，则会按照上文描述，下次 <code>_doScheduledRefresh</code> 被调用时，将刷新周期改为 <strong>500ms</strong></li>
</ul>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span> ReplicaSetMonitor::_doScheduledRefresh(<span class="keyword">const</span> CallbackHandle&amp; currentHandle) &#123;</span><br><span class="line">    ....</span><br><span class="line">    Refresher::ensureScanInProgress(_state, lk);</span><br><span class="line"></span><br><span class="line">    Milliseconds period = _state-&gt;refreshPeriod;</span><br><span class="line">    <span class="keyword">if</span> (_state-&gt;isExpedited) &#123;</span><br><span class="line">        <span class="keyword">if</span> (_state-&gt;waiters.empty()) &#123;</span><br><span class="line">            <span class="comment">// No current waiters so we can stop the expedited scanning.</span></span><br><span class="line">            _state-&gt;isExpedited = <span class="literal">false</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            period = <span class="built_in">std</span>::<span class="built_in">min</span>(period, kExpeditedRefreshPeriod);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    _scheduleRefresh(_state-&gt;now() + period, lk);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>





<h2 id="探测方式"><a href="#探测方式" class="headerlink" title="探测方式"></a>探测方式</h2><p>探测的核心 就是发送 <strong>isMaster()</strong> 命令并处理返回结果。</p>
<p>探测的中间状态记录在上文描述的 <strong>ScanState</strong> 中，主要持有几个 成员 来实现：</p>
<ul>
<li><strong>hostsToScan</strong> : 待执行队列</li>
<li><strong>possibleNodes</strong> :     非primary节点返回的node集合</li>
<li><strong>waitingFor</strong> : 已经发送命令，等待返回的集合</li>
<li><strong>triedHosts</strong> : 已经下发isMaster命令的集合</li>
</ul>
<p>探测过程有一个简单的状态机：<strong>CONTACT_HOST</strong>、<strong>WAIT</strong>、<strong>DONE</strong>，基于上面描述的 ScanState 持有的几个成员来判断：</p>
<ul>
<li><strong>CONTACT_HOST</strong> : 链接当前实例。如果 <strong>hostsToScan</strong> 中有 host，则会返回该 host 并标记状态为 <strong>CONTACT_HOST</strong></li>
<li><strong>WAIT</strong> : 等待 response 。如果 <strong>hostsToScan</strong> 为空，而 <strong>waitingFor</strong> 不为空则标记为 WAIT 状态</li>
<li><strong>DONE</strong> : Refresh 完成。如果 <code>_scan != _set-&gt;currentScan</code> 或者 <strong>hostsToScan</strong> &amp; <strong>waitingFor</strong> 均为空，则为 <strong>DONE</strong> 状态</li>
</ul>
<p>状态流转都在<code>getNextStep</code>中实现，用于<code>scheduleNetworkRequests</code>调度流转。</p>
<p><code>IsMasterReply</code> : 记录isMaster必要的返回信息</p>
<h3 id="请求下发"><a href="#请求下发" class="headerlink" title="请求下发"></a>请求下发</h3><p><code>scheduleNetworkRequests</code> 通过 <code>getNextStep</code> 依次从 <strong>hostsToScan</strong> 拿到一个host信息，并将 host 信息插入到 <strong>waitingFor</strong> 及 <strong>triedHosts</strong> 这 2 个 set 中。然后针对这个 host 调用 <code>scheduleIsMaster</code> </p>
<p><code>scheduleIsMaster</code> 构建一个 isMaster 的request ，提交给 executor ，并注册回调：</p>
<ul>
<li>如果当前 Refresher 的 <code>_scan</code> 和 <code>_set-&gt;currentScan</code> 不同，则忽略返回结果</li>
<li>如果返回结果是 ok，则调用 <code>receivedIsMaster</code>；否则调用 <code>failedHost</code></li>
</ul>
<h3 id="response处理"><a href="#response处理" class="headerlink" title="response处理"></a>response处理</h3><p><code>receivedIsMaster</code> : 将 host 从 waitingFor 中清理掉，然后构建一个 <code>IsMasterReply</code></p>
<ul>
<li>如果 <code>IsMasterReply</code> 的结果不是 ok ， 则会标记当前 host 为 fail</li>
<li>如果 reply 中 setName 和 _set 中的 name 不匹配，则会标记当前 host 为 fail</li>
<li>如果 reply 声明自己是 primary 节点， 则会调用 <code>receivedIsMasterFromMaster</code></li>
<li>找到 primary 节点以后的 reply 处理： 将 reply 更新到对应的 <code>_set</code> 的 node 上，并在 notify 中判断是否有已经满足 <code>_set-&gt;waiter</code> 的 promise，有则返回</li>
<li>未找到 primary 节点前的 reply 处理： 将 reply 的 member 全部加到 <strong>possibleNodes</strong> 中，如果在 reply 中声明了 primary 节点的地址且该 primary </li>
<li>在 <strong>triedHosts</strong> 中，则将该节点重新添加会 <strong>hostsToScan</strong>。然后将该 reply 记录到 <strong>unconfirmedReplies</strong> 中</li>
</ul>
<p><code>receivedIsMasterFromMaster</code> 处理逻辑比较多，简单整理了下：</p>
<ul>
<li>有效性判断：判断 <code>configVersion</code> / <code>electionId</code> 的有效性</li>
<li>状态存储：将 reply 的结果更新到 <code>SetState</code> 中。更新nodes / seedNodes / seedConnStr / workingConnstr</li>
<li>清理<code>ScanState</code> 中记录的信息：<strong>triedHost</strong> / <strong>waiitingFor</strong> / <strong>unconfirmedReplies</strong></li>
<li>如果 primary 有变化，则会通知所有的 listener 状态变更。</li>
</ul>
<p><code>failedHost</code> : 将 host从 <strong>waitingFor</strong> 中移除，并将node标记为 fail</p>
<p>无论<code>receivedIsMaster</code> 还是 <code>failedHost</code> 执行完成后，都会调用 <code>scheduleNetworkRequests</code> 重新调度（可能有新加入 <strong>hostsToScan</strong> 的节点）</p>
<h2 id="周边类"><a href="#周边类" class="headerlink" title="周边类"></a>周边类</h2><p><code>ReplicaSetMonitorManager</code> 是负责 <code>ReplicaSetMonitor</code> 的管理类，维护一个 map 结构 （记录 setName 和 <code>ReplicaSetMonitor</code>），一个<code>TaskExecutor</code> 用于所有 <code>ReplicaSetMonitor</code> 命令执行，以及一个<code>ReplicaSetChangeNotifier</code></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://wangxin201492.github.io/MongoDB/command/serverStatus/MongoDB-request-counter/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="wangxin201492">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="wangxin201492">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/MongoDB/command/serverStatus/MongoDB-request-counter/" itemprop="url">MongoDB 请求计数逻辑</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-04-22T17:25:43+08:00">
                2020-04-22
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/MongoDB/" itemprop="url" rel="index">
                    <span itemprop="name">MongoDB</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/MongoDB/command/" itemprop="url" rel="index">
                    <span itemprop="name">command</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/MongoDB/command/serverStatus/" itemprop="url" rel="index">
                    <span itemprop="name">serverStatus</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>mongos上一个find请求堆栈主要路径是这个样子的：</p>
<ul>
<li>#0 mongo::(anonymous namespace)::<strong>ClusterFindCmd::Invocation::run</strong> (this=0x7f3705a8e2a0, opCtx=0x7f37064b5c80, result=0x7f3705b11650) at src/mongo/s/commands/cluster_find_cmd.cpp:205</li>
<li>#1 0x00007f3701fae26a in mongo::(anonymous namespace)::<strong>execCommandClient</strong> (opCtx=0x7f37064b5c80, invocation=0x7f3705a8e2a0, request=…, result=0x7f3705b11650) at src/mongo/s/commands/strategy.cpp:303</li>
<li>#2 0x00007f3701faff38 in mongo::(anonymous namespace)::runCommand (opCtx=0x7f37064b5c80, request=…, opType=mongo::dbMsg, replyBuilder=0x7f3705b11650, errorBuilder=0x7f36eeb1adc0) at src/mongo/s/commands/strategy.cpp:489</li>
<li>#3 0x00007f3701fb1f76 in mongo::Strategy::clientCommand (opCtx=0x7f37064b5c80, m=…) at src/mongo/s/commands/strategy.cpp:800</li>
<li>#4 0x00007f3701e243cc in mongo::ServiceEntryPointMongos::handleRequest (this=0x7f37058f6680, opCtx=0x7f37064b5c80, message=…) at src/mongo/s/service_entry_point_mongos.cpp:95</li>
<li>#5 0x00007f3701e7d5e2 in mongo::<strong>ServiceStateMachine::_processMessage</strong> (this=0x7f3705ad6010, guard=…) at src/mongo/transport/service_state_machine.cpp:452</li>
</ul>
<p><code>db.serverStatus()</code> 输出结果中有3个地方对请求进行了计数，这里简单整理下</p>
<ol>
<li><code>db.serverStatus().network.numRequests</code>(简称<strong>requests计数</strong>） – 对应在堆栈中#5（即 <code>ServiceStateMachine::_processMessage()</code>）进行计数。表示<strong>接收的网络包数量</strong></li>
<li><code>db.serverStatus().metrics.commands.*.total &amp; failed</code>（简称<strong>metrics计数</strong>） – 对应在堆栈中#1（即 <code>execCommandClient()</code> ）进行计数。表示<strong>不同命令执行的次数</strong></li>
<li><code>db.serverStatus().opcounters</code>（简称<strong>opcounters计数</strong>） – 对应在堆栈中#0（即 <code>Invocation::run()</code>）即进行计数。表示<strong>requests计数</strong></li>
</ol>
<p><strong>requests计数</strong>和<strong>metrics计数</strong>的逻辑是固定的，而对于opcounters计数会根据请求的不同有一定gap。</p>
<h2 id="opcounters-计数分析"><a href="#opcounters-计数分析" class="headerlink" title="opcounters 计数分析"></a>opcounters 计数分析</h2><p><code>db.serverStatus().opcounters</code> 包含如下结果：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">mongos&gt; db.serverStatus().opcounters</span><br><span class="line">&#123;</span><br><span class="line">        <span class="attr">"insert"</span> : NumberLong(<span class="number">6</span>),</span><br><span class="line">        <span class="attr">"query"</span> : NumberLong(<span class="number">1</span>),</span><br><span class="line">        <span class="attr">"update"</span> : NumberLong(<span class="number">2</span>),</span><br><span class="line">        <span class="attr">"delete"</span> : NumberLong(<span class="number">0</span>),</span><br><span class="line">        <span class="attr">"getmore"</span> : NumberLong(<span class="number">0</span>),</span><br><span class="line">        <span class="attr">"command"</span> : NumberLong(<span class="number">75</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p>在<code>ServiceEntryPointMongos::handleRequest()</code>中对计数场景进行了区分：</p>
<h3 id="计数场景1：-opcode-OP-MSG-或者-opcode-OP-QUERY-且-namespace的collection部分-“-cmd”"><a href="#计数场景1：-opcode-OP-MSG-或者-opcode-OP-QUERY-且-namespace的collection部分-“-cmd”" class="headerlink" title="计数场景1：(opcode == OP_MSG) 或者 (opcode == OP_QUERY 且 namespace的collection部分 == “$cmd”)"></a>计数场景1：(<code>opcode == OP_MSG</code>) 或者 (<code>opcode == OP_QUERY</code> 且 namespace的collection部分 == “$cmd”)</h3><p>按照上面举例的find堆栈 <code>clientCommand()</code> –&gt; <code>runCommand()</code> –&gt; <code>execCommandClient()</code> –&gt; <code>Invocation::run()</code> 依次调用。这里所有的command都会继承 Command 类，该类提供一个 <code>shouldAffectCommandCounter()</code> 返回True。</p>
<ul>
<li>insert / update / delete / query / getmore 请求重写了 <code>shouldAffectCommandCounter()</code> 返回 false ，在 <code>Invocation::run()</code> 中完成计数</li>
<li>其余请求均作为 command，在 <code>execCommandClient()</code> 中完成计数</li>
</ul>
<h3 id="计数场景2：opcode-OP-QUERY-且-namespace的collection部分-“-cmd”"><a href="#计数场景2：opcode-OP-QUERY-且-namespace的collection部分-“-cmd”" class="headerlink" title="计数场景2：opcode == OP_QUERY 且 namespace的collection部分 != “$cmd”"></a>计数场景2：<code>opcode == OP_QUERY</code> 且 namespace的collection部分 != “$cmd”</h3><p>直接调用 <code>Strategy::queryOp()</code>， 并在其中完成计数</p>
<h3 id="计数场景3：opcode-OP-GET-MORE"><a href="#计数场景3：opcode-OP-GET-MORE" class="headerlink" title="计数场景3：opcode == OP_GET_MORE"></a>计数场景3：<code>opcode == OP_GET_MORE</code></h3><p>直接调用 <code>Strategy::getMore()</code>，并在其中完成计数</p>
<h3 id="计数场景4：opcode-OP-KILL-CURSORS"><a href="#计数场景4：opcode-OP-KILL-CURSORS" class="headerlink" title="计数场景4：opcode == OP_KILL_CURSORS"></a>计数场景4：<code>opcode == OP_KILL_CURSORS</code></h3><p>直接调用 <code>Strategy::killCursors()</code>，并在其中调用 <code>OpCounters::gotOp()</code></p>
<p>gotOp 对 OP_KILL_CURSORS / OP_REPLY 不进行计数，即这两种场景不会记录在 opcounters 中</p>
<h3 id="计数场景5：opcode-OP-INSERT-OP-UPDATE-OP-DELETE"><a href="#计数场景5：opcode-OP-INSERT-OP-UPDATE-OP-DELETE" class="headerlink" title="计数场景5：opcode == OP_INSERT / OP_UPDATE / OP_DELETE"></a>计数场景5：<code>opcode == OP_INSERT / OP_UPDATE / OP_DELETE</code></h3><p>按照场景1堆栈 <code>Strategy::writeOp()</code> –&gt; <code>runCommand()</code> –&gt; <code>execCommandClient()</code> –&gt; <code>Invocation::run()</code> 依次调用，同场景1</p>
<h3 id="对insert-update-delete-请求的计数说明"><a href="#对insert-update-delete-请求的计数说明" class="headerlink" title="对insert / update / delete 请求的计数说明"></a>对<code>insert / update / delete</code> 请求的计数说明</h3><p>对于insert / update / delete 请求，会在 <code>Invocation::run()</code> 中完成计数，但是对这3个请求的处理不是简单的+1完成的。增加的数量为 <code>batchedRequest.sizeWriteOps()</code>。由于3.6版本中新增了 OP_MSG 的协议类型，支持这3种请求携带多条数据：即 OP_MSG 协议中 <strong>kind=Document Sequence 的 sections 字段</strong>。这3种请求的具体实现，都重写了 Command 类提供的 parse 函数，基于原有的 request 构建了一个额外的 <code>BatchedCommandRequest</code> ，调用的是 <code>BatchedCommandRequest::parseInsert()</code> 函数。</p>
<p>实际执行验证来看：</p>
<p>通过insert插入一个BSONArray，opcounters.insert 会增加 array 的 size。和上面的分析是对齐的</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">mongos&gt; db.serverStatus().opcounters</span><br><span class="line">&#123;</span><br><span class="line">	<span class="attr">"insert"</span> : NumberLong(<span class="number">2</span>),</span><br><span class="line">	<span class="attr">"query"</span> : NumberLong(<span class="number">0</span>),</span><br><span class="line">	<span class="attr">"update"</span> : NumberLong(<span class="number">0</span>),</span><br><span class="line">	<span class="attr">"delete"</span> : NumberLong(<span class="number">0</span>),</span><br><span class="line">	<span class="attr">"getmore"</span> : NumberLong(<span class="number">0</span>),</span><br><span class="line">	<span class="attr">"command"</span> : NumberLong(<span class="number">58</span>)</span><br><span class="line">&#125;</span><br><span class="line">mongos&gt; db.collection.insert([&#123;name: "B"&#125;,&#123;name: "C"&#125;])</span><br><span class="line">BulkWriteResult(&#123;</span><br><span class="line">	"writeErrors" : [ ],</span><br><span class="line">	"writeConcernErrors" : [ ],</span><br><span class="line">	"nInserted" : 2,</span><br><span class="line">	"nUpserted" : 0,</span><br><span class="line">	"nMatched" : 0,</span><br><span class="line">	"nModified" : 0,</span><br><span class="line">	"nRemoved" : 0,</span><br><span class="line">	"upserted" : [ ]</span><br><span class="line">&#125;)</span><br><span class="line">mongos&gt; db.serverStatus().opcounters</span><br><span class="line">&#123;</span><br><span class="line">	<span class="attr">"insert"</span> : NumberLong(<span class="number">4</span>),</span><br><span class="line">	<span class="attr">"query"</span> : NumberLong(<span class="number">0</span>),</span><br><span class="line">	<span class="attr">"update"</span> : NumberLong(<span class="number">0</span>),</span><br><span class="line">	<span class="attr">"delete"</span> : NumberLong(<span class="number">0</span>),</span><br><span class="line">	<span class="attr">"getmore"</span> : NumberLong(<span class="number">0</span>),</span><br><span class="line">	<span class="attr">"command"</span> : NumberLong(<span class="number">62</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p>而 <code>db.colleciton.update()</code> / <code>db.colleciton.delete()</code> 并不像 <code>insert()</code> 一样支持多条记录的修改。这几个函数都是被 mongo shell 封装过的，具体通过 insert / update / delete 进行多条document修改可以参考<a href="https://docs.mongodb.com/manual/reference/command/nav-crud/" target="_blank" rel="noopener">官网文档</a>中提供的命令，分别对应有 inserts / updates / deletes 字段支持多条document修改</p>
<p><strong>Notice:</strong> 按照上面的分析，对于opcode == OP_QUERY / OP_GET_MORE / OP_KILL_CURSORS 的场景，对metrics计数应该是有缺失的。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://wangxin201492.github.io/MongoDB/command/serverStatus/MongoDB-serverStatus/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="wangxin201492">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="wangxin201492">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/MongoDB/command/serverStatus/MongoDB-serverStatus/" itemprop="url">MongoDB serverStatus实现原理</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-04-21T13:15:09+08:00">
                2020-04-21
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/MongoDB/" itemprop="url" rel="index">
                    <span itemprop="name">MongoDB</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/MongoDB/command/" itemprop="url" rel="index">
                    <span itemprop="name">command</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/MongoDB/command/serverStatus/" itemprop="url" rel="index">
                    <span itemprop="name">serverStatus</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p> <code>CmdServerStatus</code> 的 run() 函数是 <code>serverStatus</code> 命令的具体实现</p>
<ul>
<li>首先将一些全局信息添加到result中</li>
<li>遍历<code>_sections</code>，调用<code>appendSection</code>，将所有注册的<code>Section</code>结果添加到result中</li>
<li>调用<code>MetricTree::theMetricTree-&gt;appendTo()</code>，将所有<code>Metric</code>指标添加到result中</li>
<li>其他一些信息的补充</li>
</ul>
<p>同时 <code>CmdServerStatus</code> 还维护了一个 <code>_sections</code> （map结构）存储section名称和具体 <code>ServerStatusSection</code> 的对应关系。提供 <code>addSection</code> 函数将制定section添加到 <code>_sections</code> 中</p>
<h2 id="Section指标"><a href="#Section指标" class="headerlink" title="Section指标"></a>Section指标</h2><p><code>ServerStatusSection</code> 是所有 <code>section</code> 指标的基类，构造方法调用 <code>CmdServerStatusInstantiator::getInstance()-&gt;addSection()</code> 将自身注册到 <code>CmdServerStatus</code> 中。并声明 virtual 函数 <code>includeByDefault</code> , <code>addRequiredPrivileges</code> , <code>generateSection</code> , <code>appendSection</code> 由子类定义实现，子类主要需要按需求定义<code>includeByDefault</code> , <code>generateSection</code> 的具体实现。</p>
<ul>
<li><code>includeByDefault</code> 用于说明是否默认被包含</li>
<li><code>generateSection</code>&amp;<code>appendSection</code>   一般实现其中一个即可，父类方法中<code>appendSection</code> 调用了 <code>generateSection</code> ，所以一般只需要实现 <code>generateSection</code> 即可。</li>
</ul>
<p><code>CmdServerStatusInstantiator</code> 是包装 <code>CmdServerStatus</code> 用于获取 <code>CmdServerStatus</code> 单例对象的一个struct，提供 <code>getInstance()</code> 完成单例对象获取。所以上面讲到的 <code>ServerStatusSection</code> 构造时调用 <code>CmdServerStatusInstantiator::getInstance()-&gt;addSection()</code> ，最终完成了自身到 <code>CmdServerStatus</code> 的 _sections 注册。</p>
<p>serverStatus命令运行时将遍历自身的 _sections ，依次根据 <code>includeByDefault</code> 配置，调用其 appendSection 完成 response BSON 的构建。</p>
<blockquote>
<p>其他 Command 都是在类声明的时候同时定义了一个对象，完成到 CommandMap 的注册。而 <code>CmdServerStatus</code> 由于需要 <code>CmdServerStatusInstantiator</code> 构建单例对象，所以是在 <code>CmdServerStatusInstantiator</code> 声明时定义了一个对象，完成 <code>CmdServerStatus</code> 到 CommandMap 的注册行为。</p>
</blockquote>
<h2 id="Metric指标"><a href="#Metric指标" class="headerlink" title="Metric指标"></a>Metric指标</h2><p><code>MetricTree</code>维护了一个树状结构(下文简称Tree) 用于存储所有的 metric指标 及其 path 对应关系，同时提供一个静态变量 <code>theMetricTree</code> 对外提供服务。同时提供 <code>add</code> 和 <code>appendTo</code> 函数分别用于将 Tree 添加到 <code>theMetricTree</code> 以及将 Tree 的数据以BSON的形式输出。</p>
<ul>
<li><p><code>add</code> 函数用于将 <code>ServerStatusMetric</code> 添加到 <code>Tree</code> : <code>Tree</code> 维护 <code>metrics path</code> 和 <code>ServerStatusMetric</code> 的对应关系，内部是由 2 个 map 构成的，如果当前 <code>metrics path</code> 是叶子节点（即 path 中不存在”.”），那么存储到``path –&gt; ServerStatusMetric<code>的 map 中，反之取出 path 的第一级路径，存储到 第一级路径 --&gt;</code>MetricTree` （不存在则新加一个） ，然后递归调用完成添加</p>
</li>
<li><ul>
<li>如果 path 是以 “.” 为开头，则添加到 Tree 的顶级路径，否则会在提供的 path 前添加 “metrics.” 前缀（即添加到metrics的子节点上）</li>
</ul>
</li>
<li><p><code>appendTo</code> 函数用于将 <code>Tree</code> 的数据以BSON的形式输出 ： 对于非叶子节点，会递归调用 <code>appendTo</code> 函数。对于叶子节点则会调用 <code>ServerStatusMetric</code> 的 <code>appendAtLeaf</code> 函数。最终根据所有 <code>ServerStatusMetric</code> 的 path 产生对应的的BSON</p>
</li>
</ul>
<p><code>ServerStatusMetric</code> 是所有 metric指标 的基类，主要提供构造方法调用 <code>MetricTree::theMetricTree-&gt;add(this)</code> 将自身注册到 <code>MetricTree</code> 中。并声明一个 <code>virtual appendAtLeaf</code> 函数由子类定义实现。该类有4个子类：</p>
<ul>
<li><p>模板类 <code>ServerStatusMetricField</code> 是一个被广泛应用的子类。增加一个T，用于实现大多数需求：都是 k-v 的结构， <code>appendAtLeaf</code>将 <strong>k &amp; v</strong> 直接append到bson中</p>
</li>
<li><ul>
<li>举例场景：所有command的一个成员变量，用于做类似命令与请求次数的绑定，便于serverStatus拿到结果</li>
</ul>
</li>
<li><p><code>MemBase (= .mem.bits )</code> ，获取MongoDB使用的内存信息</p>
</li>
<li><p><code>ClusterCursorStats (= cursor )</code>，cursor 信息</p>
</li>
<li><p><code>ReplExecutorSSM (= repl.executor )</code>，// TODO</p>
</li>
</ul>
<p>serverStatus命令运行时，将调用 <code>theMetricTree</code> 的 <code>appendTo</code> 函数，完成 response BSON 的构建</p>
<h2 id="Section指标-amp-Metric指标-实现对比"><a href="#Section指标-amp-Metric指标-实现对比" class="headerlink" title="Section指标 &amp; Metric指标 实现对比"></a>Section指标 &amp; Metric指标 实现对比</h2><p>ServerStatusMetric 和 ServerStatusSection 下文统称为Impl</p>
<table>
<thead>
<tr>
<th></th>
<th>Section指标</th>
<th>Metric指标</th>
</tr>
</thead>
<tbody><tr>
<td>都有一个单例的对象管理</td>
<td>CmdServerStatusInstantiator::getInstance()</td>
<td>MetricTree::theMetricTree</td>
</tr>
<tr>
<td>都是 name – Impl  的对应关系</td>
<td>CmdServerStatus  中_sections是一个map结构  name – ServerStatusSection</td>
<td>ServerStatusMetric中基于2个map结构实现了一个树状结构  叶子节点也都是  name – ServerStatusMetric</td>
</tr>
<tr>
<td>Impl都提供一个函数将结果  append 到 response 中</td>
<td>generateSection&amp;appendSection</td>
<td>appendTo</td>
</tr>
</tbody></table>
<p>区别应该有2点：</p>
<ol>
<li><code>ServerStatusSection</code>的append函数 <code>generateSection</code>&amp;<code>appendSection</code> 包含了 opCtx 和 configElement 。定义分别是<ul>
<li>`virtual BSONObj generateSection(OperationContext* opCtx, const BSONElement&amp;      configElement) const;``</li>
<li>``virtual void appendSection(OperationContext* opCtx, const BSONElement&amp;      configElement, BSONObjBuilder* result) const;`</li>
</ul>
</li>
<li><code>ServerStatusSection</code>提供了 <code>includeByDefault</code> 和 <code>addRequiredPrivileges</code> 对输出结构的控制力更强一些</li>
</ol>
<p>看起来是对于serverStatus默认添加且是计数行为的使用 <code>ServerStatusMetric</code> 比较方便简单一些。其他情况尤其对于 opCtx 有依赖或者需要控制对serverStatus输出的还是使用 <code>ServerStatusSection</code> 操控力更强一些。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://wangxin201492.github.io/linux/linux-subsys-IO/linux-io-overview/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="wangxin201492">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="wangxin201492">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/linux/linux-subsys-IO/linux-io-overview/" itemprop="url">Linux IO子系统</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-02-20T16:00:27+08:00">
                2020-02-20
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/linux/" itemprop="url" rel="index">
                    <span itemprop="name">linux</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/linux/linux-subsys-IO/" itemprop="url" rel="index">
                    <span itemprop="name">linux_subsys_IO</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="用于IO读写的函数"><a href="#用于IO读写的函数" class="headerlink" title="用于IO读写的函数"></a>用于IO读写的函数</h2><p>应用程序通过<code>read</code>/<code>write</code>/<code>sync</code>函数和底层交互进行读写。读写过程依次会经历<code>stdio buffer</code>/<code>kernel buffer</code>/<code>disk</code>。大致流程见下图【图1】：<br><img src="https://wangxin201492.github.io/techImages/linux-io-buffers.png" alt="linux-io-buffers.png"><br><code>read</code>用于数据读取，<code>write</code>用于数据写入，这两个行为默认情况下(<code>bufferedIO</code>)都是写入<code>kernel buffer</code>中，而<code>sync</code>则是将数据从<code>kernel buffer</code>刷入<code>disk</code></p>
<h4 id="read-write-sync相关的函数区分"><a href="#read-write-sync相关的函数区分" class="headerlink" title="read/write/sync相关的函数区分"></a><code>read</code>/<code>write</code>/<code>sync</code>相关的函数区分</h4><p><img src="https://wangxin201492.github.io/techImages/linux-io-function-read-write-sync.png" alt="linux-io-function-read-write-sync.png"><br>上图【图2】描述的比较清楚</p>
<ul>
<li><code>fread</code>/<code>fwrite</code>是stdio提供的方法，数据仅和<code>stdio buffer</code> 交互</li>
<li><code>read</code>/<code>write</code>是系统调用，以默认<code>bufferIO</code>形式调用时，数据仅和<code>kernel buffer</code>交互。而以<code>directIO</code>形式调用，则会跨过<code>kernel buffer</code>，直接和物理设备交互<ul>
<li><code>pread</code>/<code>pwrite</code>同样是系统调用，可以认为是<code>seek</code>+<code>read</code>/<code>write</code></li>
</ul>
</li>
<li><code>fflush</code>则是将<code>stdio buffer</code>数据刷入<code>kernel buffer</code></li>
</ul>
<p><code>sync</code>/<code>fsync</code>/<code>fdatasync</code>:</p>
<ul>
<li>sync函数只是将所有修改过的块缓冲区排入写队列，然后就返回，它并不等待实际写磁盘操作结束。</li>
<li>fsync将内核缓冲区中的内容真正写入磁盘</li>
<li>fdatasync函数类似于fsync，但它只影响文件的数据部分。而除数据外，fsync还会同步更新文件的属性。</li>
</ul>
<p>相关阅读：<a href="https://luoming1224.github.io/2018/11/30/[Unix%E7%BC%96%E7%A8%8B]fread%20fwrite%20fflush%E5%AE%9E%E7%8E%B0/" target="_blank" rel="noopener">https://luoming1224.github.io/2018/11/30/[Unix%E7%BC%96%E7%A8%8B]fread%20fwrite%20fflush%E5%AE%9E%E7%8E%B0/</a></p>
<h3 id="一次完整的读取流程简述"><a href="#一次完整的读取流程简述" class="headerlink" title="一次完整的读取流程简述"></a>一次完整的读取流程简述</h3><p>IO简化的技术栈【图3】中也有相关描述，更加直观一些：<br><img src="https://wangxin201492.github.io/techImages/linux-io-stack-overview.png" alt="linux-io-stack-overview.png"></p>
<p>传统的Buffered IO使用read读取文件的过程什么样的？假设要去读一个冷文件（Cache中不存在），open(2)打开文件内核后建立了一系列的数据结构，接下来调用read(2)，到达文件系统这一层，发现Page Cache中不存在该位置的磁盘映射，然后创建相应的Page Cache并和相关的扇区关联。然后请求继续到达块设备层，在IO队列里排队，接受一系列的调度后到达设备驱动层，此时一般使用DMA方式读取相应的磁盘扇区到Cache中，然后read(2)拷贝数据到用户提供的用户态buffer中去（read(2)的参数指出的）。</p>
<h2 id="IO读写的一些重要特性"><a href="#IO读写的一些重要特性" class="headerlink" title="IO读写的一些重要特性"></a>IO读写的一些重要特性</h2><h3 id="IO类型"><a href="#IO类型" class="headerlink" title="IO类型"></a>IO类型</h3><h4 id="根据是否利用标准库缓存，可以把文件I-O分为缓冲I-O与非缓冲I-O"><a href="#根据是否利用标准库缓存，可以把文件I-O分为缓冲I-O与非缓冲I-O" class="headerlink" title="根据是否利用标准库缓存，可以把文件I/O分为缓冲I/O与非缓冲I/O"></a>根据是否利用标准库缓存，可以把文件I/O分为缓冲I/O与非缓冲I/O</h4><p>缓冲I/O，是指利用标准库缓存来加速文件的访问，而标准库内部再通过系统调用访问文件<br>非缓冲I/O，是指通过系统调用来访问文件，不再经过标准库缓存<br>注意，这里的 缓冲，是指标准库内部实现的缓存，比如很多程序到换行时才真正输出，而换行之前是被标准库暂时缓存起来了</p>
<h4 id="根据是否利用操作系统的页缓存，可以把文件I-O分为直接I-O和非直接I-O"><a href="#根据是否利用操作系统的页缓存，可以把文件I-O分为直接I-O和非直接I-O" class="headerlink" title="根据是否利用操作系统的页缓存，可以把文件I/O分为直接I/O和非直接I/O"></a>根据是否利用操作系统的页缓存，可以把文件I/O分为直接I/O和非直接I/O</h4><p>直接I/O，是指跳过操作系统页缓存，直接跟文件系统交互来访问文件<br>非直接I/O，在文件读写时，先经过系统的页缓存，然后再由内核或额外的系统调用，真正写入磁盘<br>要实现直接I/O，需要在系统调用中指定O_DIRECT标志，不设置默认是非直接I/O<br>注意，直接I/O和非直接I/O本质上还是和文件系统交互，如果在数据库等场景中，可以跳过文件系统读写磁盘的情况，就是裸I/</p>
<h4 id="根据应用程序是否阻塞自身运行，可以把文件I-O分为阻塞I-O和非阻塞I-O"><a href="#根据应用程序是否阻塞自身运行，可以把文件I-O分为阻塞I-O和非阻塞I-O" class="headerlink" title="根据应用程序是否阻塞自身运行，可以把文件I/O分为阻塞I/O和非阻塞I/O"></a>根据应用程序是否阻塞自身运行，可以把文件I/O分为阻塞I/O和非阻塞I/O</h4><h4 id="是指应用程序执行I-O操作后，如果没有获得响应，就会阻塞当前线程，自然不能执行其他任务"><a href="#是指应用程序执行I-O操作后，如果没有获得响应，就会阻塞当前线程，自然不能执行其他任务" class="headerlink" title="是指应用程序执行I/O操作后，如果没有获得响应，就会阻塞当前线程，自然不能执行其他任务"></a>是指应用程序执行I/O操作后，如果没有获得响应，就会阻塞当前线程，自然不能执行其他任务</h4><p>非阻塞I/O，是指应用程序执行I/O操作后，不会阻塞当前的线程，可以继续执行其他的人物，随后再通过轮询或者事件通知的形式，获取调用的结果<br>比如访问管道或者网络套接字时，设置O_NONBLOCK标志，就表示用非阻塞方式访问，默认是阻塞访问</p>
<h4 id="根据是否等待响应结果，可以把文件I-O分为同步和异步I-O"><a href="#根据是否等待响应结果，可以把文件I-O分为同步和异步I-O" class="headerlink" title="根据是否等待响应结果，可以把文件I/O分为同步和异步I/O"></a>根据是否等待响应结果，可以把文件I/O分为同步和异步I/O</h4><p>同步I/O，是指应用程序执行I/O操作后，要一直等到整个I/O完成后，才能获得I/O响应<br>异步I/O，是指应用程序执行I/O操作后，不用等待完成和完成后的响应，而是继续执行就可以，等到这次I/O完成后，响应会用事件通知的方式，告诉应用程序</p>
<h4 id="顺序访问-Sequential-Access-amp-随机访问-Random-Access"><a href="#顺序访问-Sequential-Access-amp-随机访问-Random-Access" class="headerlink" title="顺序访问(Sequential Access)&amp;随机访问(Random Access)"></a>顺序访问(Sequential Access)&amp;随机访问(Random Access)</h4><p>连续和随机，取决于本次IO的初始扇区地址，和上一次IO的结束扇区地址是否连续。如果是，则本次IO是一个连续IO；如果不连续，算一次随机IO。</p>
<ul>
<li>连续IO：因为本次初始扇区和上次结束扇区相隔很近，则磁头几乎不用换道或换道时间极短；</li>
<li>随机IO：磁头需要很长的换道时间，如果随机IO很多，导致磁头不停换道，效率会大大降底</li>
</ul>
<h3 id="磁盘预读-read-ahead"><a href="#磁盘预读-read-ahead" class="headerlink" title="磁盘预读(read ahead)"></a>磁盘预读(read ahead)</h3><h3 id="write-back、write-through、page-cache"><a href="#write-back、write-through、page-cache" class="headerlink" title="write back、write through、page cache"></a>write back、write through、page cache</h3><h3 id="读写过程中的数据拷贝（zero-copy）"><a href="#读写过程中的数据拷贝（zero-copy）" class="headerlink" title="读写过程中的数据拷贝（zero-copy）"></a>读写过程中的数据拷贝（zero-copy）</h3><p>整个过程有几次拷贝？从磁盘到Page Cache算第一次的话，从Page Cache到用户态buffer就是第二次了。</p>
<p>而mmap(2)做了什么？mmap(2)直接把Page Cache映射到了用户态的地址空间里了，所以mmap(2)的方式读文件是没有第二次拷贝过程的。</p>
<p>那Direct IO做了什么？这个机制更狠，直接让用户态和块IO层对接，直接放弃Page Cache，从磁盘直接和用户态拷贝数据。好处是什么？写操作直接映射进程的buffer到磁盘扇区，以DMA的方式传输数据，减少了原本需要到Page Cache层的一次拷贝，提升了写的效率。对于读而言，第一次肯定也是快于传统的方式的，但是之后的读就不如传统方式了（当然也可以在用户态自己做Cache，有些商用数据库就是这么做的）。</p>
<blockquote>
<p>除了传统的Buffered IO可以比较自由的用偏移+长度的方式读写文件之外，mmap(2)和Direct IO均有数据按页对齐的要求，Direct IO还限制读写必须是底层存储设备块大小的整数倍（甚至Linux 2.4还要求是文件系统逻辑块的整数倍）。所以接口越来越底层，换来表面上的效率提升的背后，需要在应用程序这一层做更多的事情。所以想用好这些高级特性，除了深刻理解其背后的机制之外，也要在系统设计上下一番功夫。</p>
</blockquote>
<h3 id="顺序IO模式-Queue-Mode-并发IO模式-Burst-Mode"><a href="#顺序IO模式-Queue-Mode-并发IO模式-Burst-Mode" class="headerlink" title="顺序IO模式(Queue Mode)/并发IO模式(Burst Mode)"></a>顺序IO模式(Queue Mode)/并发IO模式(Burst Mode)</h3><p>磁盘控制器可能会一次对磁盘组发出一连串的IO命令，如果磁盘组一次只能执行一个IO命令时称为顺序IO;当磁盘组能同时执行多个IO命令时，称为并发IO。</p>
<p>并发IO只能发生在由多个磁盘组成的磁盘组上，单块磁盘只能一次处理一个IO命令。</p>
<h3 id="缺页中断（Page-Fault）"><a href="#缺页中断（Page-Fault）" class="headerlink" title="缺页中断（Page Fault）"></a>缺页中断（Page Fault）</h3><h3 id="经验总结"><a href="#经验总结" class="headerlink" title="经验总结"></a>经验总结</h3><ol>
<li>提高IO效率原则： 顺序写，随机读</li>
<li>重点监控 rkB/s 和 和 wkB/s</li>
<li>%util接近100%，说明产生的I/O请求太多，I/O系统已经满负荷，该磁盘可能存在瓶颈</li>
<li>await与svctm相差很大的时候，要注意磁盘的IO性能。差值越小，说明队列时间越短，反之则队列时间越长。说明系统出了问题。</li>
</ol>
<p>规避IO负载过高：</p>
<ul>
<li>如果服务器用来做日志分析，注意随机读和顺序写，避免定期的压缩、解压大日志。</li>
<li>如果是前端应用服务器，要避免程序频繁打本地日志、或者异常日志</li>
<li>如果是存储服务（mysql、nosql），尽量将服务部署在单独的节点上，做读写分离降低压力</li>
</ul>
<h3 id="相关阅读"><a href="#相关阅读" class="headerlink" title="相关阅读"></a>相关阅读</h3><ol>
<li><a href="https://www.cnblogs.com/muahao/p/6596545.html" target="_blank" rel="noopener">https://www.cnblogs.com/muahao/p/6596545.html</a></li>
<li><a href="https://testerhome.com/articles/21493" target="_blank" rel="noopener">https://testerhome.com/articles/21493</a></li>
<li><a href="http://blog.chinaunix.net/uid-667478-id-2384354.html" target="_blank" rel="noopener">http://blog.chinaunix.net/uid-667478-id-2384354.html</a></li>
<li><a href="http://www.0xffffff.org/2017/05/01/41-linux-io/" target="_blank" rel="noopener">http://www.0xffffff.org/2017/05/01/41-linux-io/</a></li>
<li><a href="https://blog.csdn.net/hixiaoxiaoniao/article/details/86295712" target="_blank" rel="noopener">https://blog.csdn.net/hixiaoxiaoniao/article/details/86295712</a></li>
</ol>
<hr>
<h1 id="IO栈及各层功能"><a href="#IO栈及各层功能" class="headerlink" title="IO栈及各层功能"></a>IO栈及各层功能</h1><p>上文【图3】中可以看到，IO行为依次经历“应用层”、“内核层”、“块层”、“设备层”和磁盘交互。按照下图将这个层次再进一步的划分下：“文件系统层”（包含“VFS”、“Page Cache”）、“Block层”（包含“device mapper”）、“device层”</p>
<ul>
<li>文件系统层，以 write(2) 为例，内核拷贝了write(2)参数指定的用户态数据到文件系统Cache中，并适时向下层同步</li>
<li>块层，管理块设备的IO队列，对IO请求进行合并、排序（还记得操作系统课程学习过的IO调度算法吗？）</li>
<li>设备层，通过DMA与内存直接交互，完成数据和具体设备之间的交互</li>
</ul>
<p><img src="https://wangxin201492.github.io/techImages/linux-io-stack-overview-detail.png" alt="linux-io-stack-overview-detail.png"></p>
<h2 id="文件系统层"><a href="#文件系统层" class="headerlink" title="文件系统层"></a>文件系统层</h2><h3 id="缺页中断-–-page-fault"><a href="#缺页中断-–-page-fault" class="headerlink" title="缺页中断 – page fault"></a>缺页中断 – page fault</h3><p>当程序启动的时候，Linux 内核首先检查 CPU 的缓存和物理内存，如果数据已经在内存里就忽略，如果数据不在内存里就引起一个<strong>缺页中断（Page Fault）</strong>，然后从硬盘读取缺页，并把缺页缓存到物理内存里。<br>缺页中断可分为主缺页中断（Major Page Fault）和次缺页中断（Minor Page Fault）</p>
<ul>
<li>要从磁盘读取数据而产生的中断是主缺页中断</li>
<li>数据已经被读入内存并被缓存起来，从内存缓存区中而不是直接从硬盘中读取数据而产生的中断是次 缺页中断(page cache?)</li>
</ul>
<h3 id="磁盘预读-–-read-ahead"><a href="#磁盘预读-–-read-ahead" class="headerlink" title="磁盘预读 – read ahead"></a>磁盘预读 – read ahead</h3><h4 id="顺序性检测"><a href="#顺序性检测" class="headerlink" title="顺序性检测"></a>顺序性检测</h4><p>为了保证预读命中率，Linux只对顺序读(sequential read)进行预读。内核通过验证如下两个条件来判定一个read()是否顺序读：</p>
<ol>
<li>这是文件被打开后的第一次读，并且读的是文件首部；</li>
<li>当前的读请求与前一（记录的）读请求在文件内的位置是连续的。</li>
</ol>
<p>如果不满足上述顺序性条件，就判定为随机读</p>
<h4 id="预读的大小"><a href="#预读的大小" class="headerlink" title="预读的大小"></a>预读的大小</h4><p>Linux采用了一个快速的窗口扩张过程：</p>
<ul>
<li>首次预读： readahead_size = read_size * 2; // or *4</li>
<li>后续预读： readahead_size *= 2;<ul>
<li>后续的预读窗口将逐次倍增，直到达到系统设定的最大预读大小，其缺省值是128KB。</li>
<li>调整大小：blockdev –setra 2048 /dev/sda</li>
</ul>
</li>
</ul>
<h3 id="page-cache"><a href="#page-cache" class="headerlink" title="page cache"></a>page cache</h3><p>page cache有三种类型：</p>
<ol>
<li>Read pages只读页（或代码页）<ul>
<li>那些通过主缺页中断从硬盘读取的页面，包括不能修改的静态文件、可执行文件、库文件等。当内核需要它们的时候把它们读到 内存中，当内存不足的时候，内核就释放它们到空闲列表，当程序再次需要它们的时候需要通过缺页中断再次读到内存。</li>
</ul>
</li>
<li>Dirty pages，脏页<ul>
<li>指那些在内存中被修改过的数据页，比如文本文件等。这些文件由 pdflush 负责同步到硬盘，内存不足的时候由 kswapd 和 pdflush 把数据写回硬盘并释放内存。</li>
</ul>
</li>
<li>Anonymous pages，匿名页<ul>
<li>那些属于某个进程但是又和任何文件无关联，不能被同步到硬盘上，内存不足的时候由 kswapd 负责将它们写到交换分区并释放内存。</li>
</ul>
</li>
</ol>
<h3 id="Write-Through（写穿）和Write-back（写回）-–-page-cache同步"><a href="#Write-Through（写穿）和Write-back（写回）-–-page-cache同步" class="headerlink" title="Write Through（写穿）和Write back（写回） – page cache同步"></a>Write Through（写穿）和Write back（写回） – page cache同步</h3><p>广义上Cache的同步方式有两种，即Write Through（写穿）和Write back（写回）. 从名字上就能看出这两种方式都是从写操作的不同处理方式引出的概念（纯读的话就不存在Cache一致性了，不是么）。对应到Linux的Page Cache上</p>
<ul>
<li>Write Through就是指write(2)操作将数据拷贝到Page Cache后立即和下层进行同步的写操作，完成下层的更新后才返回。</li>
<li>而Write back正好相反，指的是写完Page Cache就可以返回了。Page Cache到下层的更新操作是异步进行的。</li>
</ul>
<p>Linux下Buffered IO默认使用的是Write back机制，即文件操作的写只写到Page Cache就返回，之后Page Cache到磁盘的更新操作是异步进行的。Page Cache中被修改的内存页称之为脏页（Dirty Page），脏页在特定的时候被一个叫做pdflush(Page Dirty Flush)的内核线程写入磁盘，写入的时机和条件如下：</p>
<p>当空闲内存低于一个特定的阈值时，内核必须将脏页写回磁盘，以便释放内存。<br>当脏页在内存中驻留时间超过一个特定的阈值时，内核必须将超时的脏页写回磁盘。<br>用户进程调用sync(2)、fsync(2)、fdatasync(2)系统调用时，内核会执行相应的写回操作。<br>刷新策略由以下几个参数决定（数值单位均为1/100秒）：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># flush每隔5秒执行一次</span><br><span class="line">root@082caa3dfb1d &#x2F; $ sysctl vm.dirty_writeback_centisecs</span><br><span class="line">vm.dirty_writeback_centisecs &#x3D; 500</span><br><span class="line"># 内存中驻留30秒以上的脏数据将由flush在下一次执行时写入磁盘</span><br><span class="line">root@082caa3dfb1d &#x2F; $ sysctl vm.dirty_expire_centisecs</span><br><span class="line">vm.dirty_expire_centisecs &#x3D; 3000</span><br><span class="line"># 若脏页占总物理内存10％以上，则触发flush把脏数据写回磁盘</span><br><span class="line">root@082caa3dfb1d &#x2F; $ sysctl vm.dirty_background_ratio</span><br><span class="line">vm.dirty_background_ratio &#x3D; 10</span><br></pre></td></tr></table></figure>

<p>默认是写回方式，如果想指定某个文件是写穿方式呢？即写操作的可靠性压倒效率的时候，能否做到呢？当然能，除了之前提到的fsync(2)之类的系统调用外，在open(2)打开文件时，传入O_SYNC这个flag即可实现。这里给篇参考文章[5]，不再赘述（更好的选择是去读TLPI相关章节）。</p>
<p>文件读写遭遇断电时，数据还安全吗？相信你有自己的答案了。使用O_SYNC或者fsync(2)刷新文件就能保证安全吗？现代磁盘一般都内置了缓存，代码层面上也只能讲数据刷新到磁盘的缓存了。当数据已经进入到磁盘的高速缓存时断电了会怎么样？这个恐怕不能一概而论了。不过可以使用hdparm -W0命令关掉这个缓存，相应的，磁盘性能必然会降低。</p>
<h3 id="文件系统与inode"><a href="#文件系统与inode" class="headerlink" title="文件系统与inode"></a>文件系统与inode</h3><p><img src="https://wangxin201492.github.io/techImages/linux-filesystem-inode.png" alt="linux-filesystem-inode.png"></p>
<p>应用程序在访问文件时都会先打开文件，在内核中，对应每个进程，都会有一个文件描述符表表示这个进程打开的文件，但是用户程序不能直接访问内核中的文件描述符表,而只能使用文件描述符表的索引（一个整数），这些索引就被称为文件描述符。当调用open 打开一个文件或创建一个新文件时,内核分配一个文件描述符并返回给用户程序,该文件描述符表项中的指针指向新打开的文件。</p>
<p>文件描述表中每一项都是一个指针，指向一个用于描述打开的文件的数据块–file对象，file对象中描述了文件的打开模式，读写位置等重要信息，当进程打开一个文件时，内核就会创建一个新的file对象。需要注意的是，file对象不是专属于某个进程的，不同进程的文件描述符表中的指针可以指向相同的file对象，从而共享这个打开的文件。file对象有引用计数，记录了引用这个对象的文件描述符个数，只有当引用计数为0时，内核才销毁file对象，因此某个进程关闭文件，不影响与之共享同一个file对象的进程。</p>
<p>file对象中包含一个指针，指向dentry对象。dentry对象代表一个独立的文件路径，如果一个文件路径被打开多次，那么会建立多个file对象，但它们都指向同一个dentry对象。inode对象代表一个独立文件，inode 对象包含了最终对文件进行操作所需的所有信息，如文件系统类型、文件的操作方法、文件的权限、访问日期等。</p>
<h3 id="文件系统磁盘布局"><a href="#文件系统磁盘布局" class="headerlink" title="文件系统磁盘布局"></a>文件系统磁盘布局</h3><p><img src="https://wangxin201492.github.io/techImages/linux-filesystem-ext-blocks.png" alt="linux-filesystem-ext-blocks.png"></p>
<p>ext3文件系统将其所管理的磁盘或者分区(引导块除外)中的块划分到不同的块组中。每个块组大小相同，当然最后一个块组所管理的块可能会少一些，其大小在文件系统创建时决定，主要取决于文件系统的块大小。每个块组包含一个块位图块，一个inode位图块，一个或多个块用于描述 inode 表和用于存储文件数据的数据块，除此之外，还有可能包含超级块和所有块组描述符表。<br>块位图用于描述该块组所管理的块的分配状态，如果某个块对应的位未置位，那么代表该块未分配，可以进行分配使用。inode位图用于描述该块组所管理的inode的分配状态，每个inode对应文件系统中唯一的一个号，如果inode位图中相应位置位，那么代表该inode已经分配出去；否则可以使用。</p>
<h3 id="日志文件系统和非日志文件系统"><a href="#日志文件系统和非日志文件系统" class="headerlink" title="日志文件系统和非日志文件系统"></a>日志文件系统和非日志文件系统</h3><p>文件内容的修改涉及到两部分：实际文件内容的修改 和 文件元(metadata)信息的修改。所以在修改一个成功之后，修改另一个之前，此时系统崩溃，就会导致两者的不一致。所以提出了日志文件系统的概念。</p>
<p>所谓的日志文件系统(Journaling file system)，就是在实际修改文件内容和文件元信息之前，将他们的修改先写到一个日志中(journal log)。这样的话，如果发生系统崩溃，就可以使用日志进行恢复。当然，写日志会对文件系统的性能有一定的影响。除了ext2之外，其它文件系统几乎都是日志文件系统。</p>
<p>日志文件系统的处理过程是：1）先写日志；2）然后写实际的文件系统；3）删除日志；</p>
<p>日志文件系统又可以分成三种类型：</p>
<ol>
<li>日志模式(journal): 将所有的元数据和数据改变均写入日志，对性能影响最大；</li>
<li>预定模式(ordered): 只记录元数据的变化, 在数据写入磁盘后再修改元数据，对性能影响中等；</li>
<li>写回模式(writeback): 只记录元数据的修改变化，对数据修改顺序无要求，对性能影响最小；</li>
</ol>
<p>我们可以在/etc/fstab 文件中修改文件系统的日志模式。<br>/dev/sdb1 /testfs ext3 defaults,data=writeback 0 0</p>
<h3 id="相关阅读-1"><a href="#相关阅读-1" class="headerlink" title="相关阅读"></a>相关阅读</h3><ol>
<li><a href="http://www.sysnote.org/2015/08/06/fs-io-map/" target="_blank" rel="noopener">http://www.sysnote.org/2015/08/06/fs-io-map/</a></li>
<li><a href="http://oliveryang.net/2016/05/linux-file-system-basic-4/" target="_blank" rel="noopener">http://oliveryang.net/2016/05/linux-file-system-basic-4/</a></li>
<li><a href="https://www.cnblogs.com/digdeep/p/4857987.html" target="_blank" rel="noopener">https://www.cnblogs.com/digdeep/p/4857987.html</a></li>
</ol>
<h2 id="Block层"><a href="#Block层" class="headerlink" title="Block层"></a>Block层</h2><h3 id="block-IO"><a href="#block-IO" class="headerlink" title="block IO"></a>block IO</h3><p>一个I/O请求进入block layer之后，可能会经历下面的过程：</p>
<ul>
<li>Remap: 可能被DM(Device Mapper)或MD(Multiple Device, Software RAID) remap到其它设备</li>
<li>Split: 可能会因为I/O请求与扇区边界未对齐、或者size太大而被分拆(split)成多个物理I/O</li>
<li>Merge: 可能会因为与其它I/O请求的物理位置相邻而合并(merge)成一个I/O</li>
<li>被IO Scheduler依照调度策略发送给driver</li>
<li>被driver提交给硬件，经过HBA、电缆（光纤、网线等）、交换机（SAN或网络）、最后到达存储设备，设备完成IO请求之后再把结果发回。</li>
</ul>
<h3 id="device-mapper层"><a href="#device-mapper层" class="headerlink" title="device mapper层"></a>device mapper层</h3><h2 id="device层"><a href="#device层" class="headerlink" title="device层"></a>device层</h2><h3 id="机械磁盘基本结构"><a href="#机械磁盘基本结构" class="headerlink" title="机械磁盘基本结构"></a>机械磁盘基本结构</h3><p><img src="https://wangxin201492.github.io/techImages/linux-disk-HDD-overview.png" alt="linux-disk-HDD-overview.png"><br>硬盘由三部分组成，物理结构，数据结构，存储容量</p>
<ul>
<li>数据结构:<ul>
<li>扇区：磁盘上每个磁道被分为若干个弧段，这些弧段便是硬盘的扇区。硬盘的第一个扇区，叫做引导扇区。</li>
<li>磁道：当磁盘旋转时，磁头若保持在一个位置上，则每个磁头都会在磁盘表面划出一个圆形轨迹，这些圆形轨迹 叫做磁道</li>
</ul>
</li>
<li>物理结构<ul>
<li>盘片：硬盘有多个盘片，每个盘片有2面。</li>
<li>磁头：每面一个磁头</li>
</ul>
</li>
<li>存储容量 = 磁头数<em>磁道数</em>每道扇区数*每扇区字节数</li>
</ul>
<h3 id="固态硬盘"><a href="#固态硬盘" class="headerlink" title="固态硬盘"></a>固态硬盘</h3><p>固态硬盘(Solid State Disk)，通常缩写为SSD，由固态电子元器件组成，固态磁盘不需要磁道寻址，所以不管是连续I/O，还是随机I/O的性能，都比机械磁盘要好得多</p>
<h4 id="机械硬盘-amp-固态硬盘"><a href="#机械硬盘-amp-固态硬盘" class="headerlink" title="机械硬盘&amp;固态硬盘"></a>机械硬盘&amp;固态硬盘</h4><p>无论机械盘还是固态磁盘，相同磁盘的随机I/O都要比连续I/O慢很多</p>
<ul>
<li>对机械磁盘来说，由于随机I/O需要更多的磁头晕倒和盘片旋转，它的性能自然比连续I/O慢</li>
<li>对于固态磁盘，虽然它的随机性能比机械硬盘好很多，但同样存在“先擦除再写入”的限制，随机读写会导致大量的垃圾回收，导致随机I/O的性能比连续I/O还是差了很多</li>
<li>连续I/O还可以通过预读取的方式，来减少I/O请求的次数，这也是其性能优异的一个原因，很多性能优化的方案，都会从这个角度出发，来优化I/O性能</li>
</ul>
<p>机械磁盘和固态硬盘还有一个最小的读写单位</p>
<ul>
<li>机械磁盘的最小读写单位是扇区，一般为512字节</li>
<li>固态硬盘的最小读写单位是页，通常大小是4KB，8KB等</li>
</ul>
<p>由于每次读写512字节这么小的单位效率很低，所以文件系统会把连续的扇区，组成逻辑块，然后以逻辑快作为最小单位来管理数据，常见的逻辑块大小是4KB，也就是连续8个扇区，或者一个独立的页，都可以组成一个逻辑块</p>
<h3 id="磁盘读取数据花费的时间"><a href="#磁盘读取数据花费的时间" class="headerlink" title="磁盘读取数据花费的时间"></a>磁盘读取数据花费的时间</h3><h4 id="寻道时间"><a href="#寻道时间" class="headerlink" title="寻道时间"></a>寻道时间</h4><p>磁盘的驱动臂(Actuator Arm)带读写磁头(Head)离开着陆区(Landing Zone，位于内圈没有数据的区域)，移动到要操作的初始数据块所在的磁道(Track)的正上方，这个过程被称为寻址(Seeking)，对应消耗的时间被称为寻址时间(Seek Time)</p>
<p>考虑到被读写的数据可能在磁盘的任意一个磁道，既有可能在磁盘的最内圈(寻址时间最短)，也可能在磁盘的最外圈(寻址时间最长)，所以在计算中我们只考虑平均寻址时间，也就是磁盘参数中标明的那个平均寻址时间，这里就采用当前最多的10krmp硬盘的5ms。</p>
<p>目前磁盘的平均寻道时间一般在3－15ms。</p>
<h4 id="旋转延迟"><a href="#旋转延迟" class="headerlink" title="旋转延迟"></a>旋转延迟</h4><p>但是找到对应磁道还不能马上读取数据，这时候磁头要等到磁盘盘片(Platter)旋转到初始数据块所在的扇区(Sector)落在读写磁头正上方的之后才能开始读取数据，在这个等待盘片旋转到可操作扇区的过程中消耗的时间称为旋转延时(Rotational Delay)</p>
<p>和寻址一样，当磁头定位到磁道之后有可能正好在要读写扇区之上，这时候是不需要额外额延时就可以立刻读写到数据，但是最坏的情况确实要磁盘旋转整整一圈之后磁头才能读取到数据，所以这里我们也考虑的是平均旋转延时，对于10krpm的磁盘就是(60s/15k)*(1/2) = 2ms。</p>
<h4 id="数据传输时间"><a href="#数据传输时间" class="headerlink" title="数据传输时间"></a>数据传输时间</h4><p>接下来就随着盘片的旋转，磁头不断的读/写相应的数据块，直到完成这次IO所需要操作的全部数据，这个过程称为数据传送(Data Transfer)，对应的时间称为传送时间(Transfer Time)</p>
<p>磁盘参数提供我们的最大的传输速度，当然要达到这种速度是很有难度的，但是这个速度却是磁盘纯读写磁盘的速度，因此只要给定了单次 IO的大小，我们就知道磁盘需要花费多少时间在数据传送上，这个时间就是IO Chunk Size / Max Transfer Rate。</p>
<p>目前IDE/ATA能达到133MB/s，SATA II可达到300MB/s的接口数据传输率</p>
<h3 id="基本单位"><a href="#基本单位" class="headerlink" title="基本单位"></a>基本单位</h3><h4 id="块（block）"><a href="#块（block）" class="headerlink" title="块（block）"></a>块（block）</h4><blockquote>
<p>在windows下叫做簇，在linux下如ext4系统中成为块(block)</p>
</blockquote>
<p>块是操作系统中最小的逻辑存储单位(虚拟出来的)，操作系统与磁盘打交道的最小单位是磁盘块，每个块可以包括2、4、8、16、32、64…2的n次方个扇区</p>
<p>优点：</p>
<ol>
<li>读取方便：由于扇区的数量比较小，数目众多在寻址时比较困难，所以操作系统就将相邻的扇区组合在一起，形成一个块，再对块进行整体的操作</li>
<li>分离对底层的依赖：操作系统忽略对底层物理存储结构的设计。通过虚拟出来磁盘块的概念，在系统中认为块是最小的单位</li>
</ol>
<h4 id="page"><a href="#page" class="headerlink" title="page"></a>page</h4><p>操作系统经常与内存和硬盘这两种存储设备进行通信，类似于“块”的概念，都需要一种虚拟的基本单位。所以，与内存操作，是虚拟一个页的概念来作为最小单位。与硬盘打交道，就是以块为最小单位。</p>
<p>获取方式：<code>/usr/bin/time -v data</code></p>
<h4 id="扇区、块-簇、page的关系"><a href="#扇区、块-簇、page的关系" class="headerlink" title="扇区、块/簇、page的关系"></a>扇区、块/簇、page的关系</h4><ol>
<li>扇区： 硬盘的最小读写单元</li>
<li>块/簇： 是操作系统针对硬盘读写的最小单元</li>
<li>page： 是内存与操作系统之间操作的最小单元</li>
</ol>
<p>大小关系：扇区 &lt;= 块/簇 &lt;= page</p>
<p>目前接触到的扇区一般为512B，块为4KB，page为4KB</p>
<h3 id="磁盘类型一些名词区分"><a href="#磁盘类型一些名词区分" class="headerlink" title="磁盘类型一些名词区分"></a>磁盘类型一些名词区分</h3><h4 id="尺寸外形"><a href="#尺寸外形" class="headerlink" title="尺寸外形"></a>尺寸外形</h4><p>也就是设备的形状和大小，通常存储设备的尺寸外形包括如下：</p>
<ul>
<li>2.5寸或者3.5寸驱动器（在SFF标准中定义）</li>
<li>M.2 和 PCI Express（PCIe）（在PCI-SIG标准中定义）</li>
</ul>
<h4 id="接口"><a href="#接口" class="headerlink" title="接口"></a>接口</h4><p>也就是设备如何与计算机通信。常见的存储设备接口包括：</p>
<ul>
<li>SATA接口，通常用于2.5寸和3.5寸硬盘，有时候一些M.2设备也会使用</li>
<li>PCI Express(PCIe)接口， 用于M.2和PCIe设备</li>
<li>SAS（串行SCSI）和FC（Fibre Channel）接口</li>
</ul>
<p>仅用于服务器领域和数据中心 PCIe接口要比SATA接口快的多，SATA3最大带宽是6Gb/s，而基于4X PCIe的M.2接口最大可以达到32Gb/s。</p>
<h4 id="协议"><a href="#协议" class="headerlink" title="协议"></a>协议</h4><p>定义了如何在计算机与设备之间传输数据。常见的协议包括：</p>
<ul>
<li>用于SATA接口的AHCI或者ATA协议</li>
<li>用于PCIe接口的NVMe协议</li>
</ul>
<h4 id="为什么NVMe会这么快"><a href="#为什么NVMe会这么快" class="headerlink" title="为什么NVMe会这么快"></a>为什么NVMe会这么快</h4><blockquote>
<p>这里说的快是基于SSD设备的，如果是机械硬盘则不然</p>
</blockquote>
<p>由于SSD本身的物理特性，其数据的访问已经非常快了，性能的瓶颈就是出在计算机与设备连接的接口和协议上面。 </p>
<ul>
<li>对于SATA的SSD，类似于一个单臂的机器人，仓库生产的很快，但机器人每次只能拿一个，搬移的速度就比较慢。</li>
<li>然而对于基于NVMe的SSD，相当于这个机器人长了数百只手，这样速度显然就比前者快的多了。</li>
</ul>
<h3 id="IOPS"><a href="#IOPS" class="headerlink" title="IOPS"></a>IOPS</h3><p>IOPS (Input/Output Per Second)即每秒的输入输出量(或读写次数)，是衡量磁盘性能的主要指标之一。IOPS是指单位时间内系统能处理的I/O请求数量，一般以每秒处理的I/O请求数量为单位，I/O请求通常为读或写数据操作请求。</p>
<h4 id="IOPS计算方法"><a href="#IOPS计算方法" class="headerlink" title="IOPS计算方法"></a>IOPS计算方法</h4><p>传统磁盘本质上一种机械装置，如FC, SAS, SATA磁盘，转速通常为5400/7200/10K/15K rpm不等。影响磁盘的关键因素是磁盘服务时间，即磁盘完成一个I/O请求所花费的时间，它由<code>寻道时间</code>、<code>旋转延迟</code>和<code>数据传输时间</code>三部分构成。</p>
<p>理论上可以计算出磁盘的最大IOPS，即<code>IOPS = 1000 ms/ (Tseek + Troatation)</code>，忽略数据传输时间。假设磁盘平均物理寻道时间为3ms, 磁盘转速为7200,10K,15K rpm，则磁盘IOPS理论最大值分别为:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">IOPS &#x3D; 1000 &#x2F; (3 + 60000&#x2F;7200&#x2F;2)  &#x3D; 140</span><br><span class="line">IOPS &#x3D; 1000 &#x2F; (3 + 60000&#x2F;10000&#x2F;2) &#x3D; 167</span><br><span class="line">IOPS &#x3D; 1000 &#x2F; (3 + 60000&#x2F;15000&#x2F;2) &#x3D; 200</span><br></pre></td></tr></table></figure>

<p>固态硬盘SSD是一种电子装置， 避免了传统磁盘在寻道和旋转上的时间花费，存储单元寻址开销大大降低，因此IOPS可以非常高，能够达到数万甚至数十万。</p>
<h3 id="传输速度-Transfer-Rate-吞吐率-Throughput"><a href="#传输速度-Transfer-Rate-吞吐率-Throughput" class="headerlink" title="传输速度(Transfer Rate)/吞吐率(Throughput)"></a>传输速度(Transfer Rate)/吞吐率(Throughput)</h3><p>现在我们要说的传输速度(另一个常见的说法是吞吐率)不是磁盘上所表明的最大传输速度或者说理想传输速度，而是磁盘在实际使用的时候从磁盘系统总线上流过的数据量。有了IOPS数据之后我们是很容易就能计算出对应的传输速度来的</p>
<p><img src="https://wangxin201492.github.io/techImages/linux-io-size-effect-iops.png" alt="linux-io-size-effect-iops.png"></p>
<p>这里一定要明确一个概念，那就是尽管上面我们使用IOPS来计算传输速度，但是实际上传输速度和IOPS是没有直接关系，在没有缓存的情况下它们共同的决定因素都是对磁盘系统的访问方式以及单个IO的大小。</p>
<p>对磁盘进行随机访问时候我们可以利用IOPS来衡量一个磁盘系统的性能，此时的传输速度不会太大;但是当对磁盘进行连续访问时，此时的IOPS已经没有了参考的价值，这个时候限制实际传输速度却是磁盘的最大传输速度。</p>
<p>因此在实际的应用当中，<strong>只会用IOPS来衡量小IO的随机读写的性能，而当要衡量大IO连续读写的性能的时候就要采用传输速度而不能是IOPS了</strong></p>
<h2 id="相关阅读-2"><a href="#相关阅读-2" class="headerlink" title="相关阅读"></a>相关阅读</h2><ol>
<li><a href="https://blog.51cto.com/14449536/2431772" target="_blank" rel="noopener">https://blog.51cto.com/14449536/2431772</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/71932170" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/71932170</a></li>
<li><a href="https://www.cnblogs.com/muahao/p/6596545.html" target="_blank" rel="noopener">https://www.cnblogs.com/muahao/p/6596545.html</a></li>
</ol>
<h3 id="内核代码分析"><a href="#内核代码分析" class="headerlink" title="内核代码分析"></a>内核代码分析</h3><ol>
<li><a href="https://zhuanlan.zhihu.com/p/56823442" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/56823442</a></li>
<li><a href="https://www.codeleading.com/article/22651695474/" target="_blank" rel="noopener">https://www.codeleading.com/article/22651695474/</a></li>
<li><a href="https://www.ibm.com/developerworks/cn/linux/l-cn-directio/index.html" target="_blank" rel="noopener">https://www.ibm.com/developerworks/cn/linux/l-cn-directio/index.html</a></li>
<li><a href="http://oenhan.com/ext3-fs-directio" target="_blank" rel="noopener">http://oenhan.com/ext3-fs-directio</a></li>
<li><a href="http://oenhan.com/linux-kernel-read" target="_blank" rel="noopener">http://oenhan.com/linux-kernel-read</a></li>
</ol>
<hr>
<h2 id="IO监控工具"><a href="#IO监控工具" class="headerlink" title="IO监控工具"></a>IO监控工具</h2><p><img src="https://wangxin201492.github.io/techImages/linux-io-utils.png" alt="linux-io-utils.png"></p>
<h3 id="iostat"><a href="#iostat" class="headerlink" title="iostat"></a>iostat</h3><p>常用<code>iostat -dx 1 100</code>。iostat(1)和sar(1)都没有指标可以衡量硬盘设备的性能，这是因为它们所依赖的/proc/diskstats不提供这项数据</p>
<ul>
<li>IOPS：r/s &amp; w/s</li>
<li>带宽：rkB/s &amp; wkB/s</li>
<li>IO合并：rrqm/s &amp; wrqm/s。如果两个I/O操作发生在相邻的数据块时，它们可以被合并成一个，以提高效率，合并的操作通常是I/O scheduler（也叫elevator）负责的</li>
<li>avgrq-sz：每个I/O的平均扇区数</li>
<li>avgqu-sz：平均未完成的I/O请求数量（手册上说是队列里的平均I/O请求数量，更恰当的理解应该是平均未完成的I/O请求数量。）</li>
<li>svctm：已被废弃的指标，没什么意义，svctm=[util/tput]。iostat(1)和sar(1)的man page上都说了不要相信svctm，该指标将被废弃</li>
<li>%util：该硬盘设备的繁忙比率。表示该设备有I/O（即非空闲）的时间比率，不考虑I/O有多少，只考虑有没有。由于现代硬盘设备都有并行处理多个I/O请求的能力，所以%util即使达到100%也不意味着设备饱和了<ul>
<li>某硬盘处理单个I/O需要0.1秒，有能力同时处理10个I/O请求，那么当10个I/O请求依次顺序提交的时候，需要1秒才能全部完成，在1秒的采样周期里%util达到100%；而如果10个I/O请求一次性提交的话，0.1秒就全部完成，在1秒的采样周期里%util只有10%。可见，即使%util高达100%，硬盘也仍然有可能还有余力处理更多的I/O请求，即没有达到饱和状态</li>
</ul>
</li>
</ul>
<h3 id="iotop"><a href="#iotop" class="headerlink" title="iotop"></a>iotop</h3><p>这两个命令,都可以按进程统计IO状况,因此可以回答你以下二个问题</p>
<p>当前系统哪些进程在占用IO,百分比是多少?<br>占用IO的进程是在读?还是在写?读写量是多少?</p>
<h3 id="pidstat"><a href="#pidstat" class="headerlink" title="pidstat"></a>pidstat</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">pidstat -u -r -d -t 1        </span><br><span class="line"># -d IO 信息,</span><br><span class="line"># -r 缺页及内存信息</span><br><span class="line"># -u CPU使用率</span><br><span class="line"># -t 以线程为统计单位</span><br><span class="line"># 1  1秒统计一次</span><br></pre></td></tr></table></figure>

<h3 id="block-dump-iodump"><a href="#block-dump-iodump" class="headerlink" title="block_dump, iodump"></a>block_dump, iodump</h3><p>iotop和 pidstat 用着很爽,但两者都依赖于/proc/pid/io文件导出的统计信息, 这个对于老一些的内核是没有的.因此只好用以上2个穷人版命令</p>
<h3 id="ioprofile"><a href="#ioprofile" class="headerlink" title="ioprofile"></a>ioprofile</h3><p>ioprofile 命令本质上是 lsof + strace, 具体下载可见 <a href="http://code.google.com/p/maatkit/" target="_blank" rel="noopener">http://code.google.com/p/maatkit/</a></p>
<p>ioprofile 可以回答你以下三个问题:</p>
<ul>
<li>当前进程某时间内,在业务层面读写了哪些文件(read, write)？</li>
<li>读写次数是多少?(read, write的调用次数)</li>
<li>读写数据量多少?(read, write的byte数)</li>
</ul>
<p>假设某个行为会触发程序一次IO动作,例如: “一个页面点击,导致后台读取A,B,C文件”<br>./io_event # 假设模拟一次IO行为,读取A文件一次, B文件500次, C文件500次</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ioprofile  -p  &#96;pidof  io_event&#96; -c count   # 读写次数</span><br><span class="line">ioprofile  -p  &#96;pidof  io_event&#96; -c times   # 读写耗时</span><br><span class="line">ioprofile  -p  &#96;pidof  io_event&#96; -c sizes    # 读写大小</span><br></pre></td></tr></table></figure>

<h3 id="相关阅读-3"><a href="#相关阅读-3" class="headerlink" title="相关阅读"></a>相关阅读</h3><ol>
<li><a href="https://www.cnblogs.com/muahao/p/6564745.html" target="_blank" rel="noopener">https://www.cnblogs.com/muahao/p/6564745.html</a></li>
<li><a href="http://linuxperf.com/?p=156" target="_blank" rel="noopener">http://linuxperf.com/?p=156</a></li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://wangxin201492.github.io/shell/shell-and-subshell/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="wangxin201492">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="wangxin201492">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/shell/shell-and-subshell/" itemprop="url">【shell】shell与子shell那团乱麻</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2015-12-16T20:01:48+08:00">
                2015-12-16
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/shell/" itemprop="url" rel="index">
                    <span itemprop="name">shell</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="1-fork-amp-source-amp-exec"><a href="#1-fork-amp-source-amp-exec" class="headerlink" title="1. fork &amp; source &amp; exec"></a>1. <code>fork</code> &amp; <code>source</code> &amp; <code>exec</code></h2><p>在运行shell脚本时候，有三种方式来调用外部的脚本，<code>exec(exec script.sh)</code>、<code>source(source script.sh)</code>、<code>fork(./script.sh)</code></p>
<h3 id="1-1-exec（exec-home-script-sh）："><a href="#1-1-exec（exec-home-script-sh）：" class="headerlink" title="1.1. exec（exec /home/script.sh）："></a>1.1. exec（exec /home/script.sh）：</h3><p>使用<code>exec</code>来调用脚本，被执行的脚本会继承当前shell的环境变量。<strong>但事实上<code>exec</code>产生了新的进程，他会把主shell的进程资源占用并替换脚本内容，继承了原主shell的PID号，即原主shell剩下的内容不会执行。</strong></p>
<h3 id="1-2-source（source-home-script-sh）"><a href="#1-2-source（source-home-script-sh）" class="headerlink" title="1.2. source（source /home/script.sh）"></a>1.2. source（source /home/script.sh）</h3><p>使用<code>source</code>或者“<code>.</code>”来调用外部脚本，<strong>不会产生新的进程</strong>，继承当前shell环境变量，而且被调用的脚本运行结束后，<strong>它拥有的环境变量和声明变量会被当前shell保留</strong>，类似将调用脚本的内容复制过来直接执行。<strong>执行完毕后原主shell继续运行。</strong></p>
<h3 id="1-3-fork（-home-script-sh）"><a href="#1-3-fork（-home-script-sh）" class="headerlink" title="1.3. fork（/home/script.sh）"></a>1.3. fork（/home/script.sh）</h3><p>直接运行脚本，会<strong>以当前shell为父进程，产生新的进程</strong>，并且<strong>继承主脚本的环境变量和声明变量</strong>。执行完毕后，<strong>主脚本不会保留其环境变量和声明变量</strong>。</p>
<p>总结：这样来看<code>fork</code>最灵活，<code>source</code>次之，<code>exec</code>最诡异。</p>
<h3 id="1-4-example"><a href="#1-4-example" class="headerlink" title="1.4. example"></a>1.4. example</h3><h5 id="主脚本"><a href="#主脚本" class="headerlink" title="主脚本"></a>主脚本</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/sh</span></span><br><span class="line">a=main</span><br><span class="line"></span><br><span class="line">echo "a is $a"</span><br><span class="line">echo "PID for parent before 2.sh:$$"</span><br><span class="line">case $1 in</span><br><span class="line">  exec)</span><br><span class="line">    echo "using exec"</span><br><span class="line">    exec ./2.sh ;;</span><br><span class="line">  source)</span><br><span class="line">    echo "using sourcing"</span><br><span class="line">    source ./2.sh ;;</span><br><span class="line">  *)</span><br><span class="line">    echo "using fork"</span><br><span class="line">    ./2.sh ;;</span><br><span class="line">esac</span><br><span class="line"></span><br><span class="line">echo "PID FOR parent after 2.sh :$$"</span><br><span class="line"></span><br><span class="line">echo "now main.sh a is $a"</span><br><span class="line">echo "$b"</span><br></pre></td></tr></table></figure>

<h5 id="调用脚本：2-sh"><a href="#调用脚本：2-sh" class="headerlink" title="调用脚本：2.sh"></a>调用脚本：2.sh</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/sh</span></span><br><span class="line">echo "PID FOR 2.SH:$$"</span><br><span class="line"></span><br><span class="line">echo  "2.sh get a from main.sh is $a"</span><br><span class="line"></span><br><span class="line">a=2.sh</span><br><span class="line">export a</span><br><span class="line">b=3.sh</span><br><span class="line"></span><br><span class="line">echo "now 2.sh a is $a"</span><br></pre></td></tr></table></figure>

<h5 id="执行结果："><a href="#执行结果：" class="headerlink" title="执行结果："></a>执行结果：</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> ./main.sh <span class="built_in">exec</span></span></span><br><span class="line">a is main</span><br><span class="line">PID for parent before 2.sh:19026</span><br><span class="line">using exec</span><br><span class="line">PID FOR 2.SH:19026</span><br><span class="line">2.sh get a from main.sh is main</span><br><span class="line">now a is 2.sh</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> ./main.sh <span class="built_in">source</span></span></span><br><span class="line">a is main</span><br><span class="line">PID for parent before 2.sh:19027</span><br><span class="line">using sourcing</span><br><span class="line">PID FOR 2.SH:19027</span><br><span class="line">2.sh get a from main.sh is main</span><br><span class="line">now a is 2.sh</span><br><span class="line">PID FOR parent after 2.sh :19027</span><br><span class="line">now main.sh a is 2.sh</span><br><span class="line">3.sh</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> ./main.sh fork</span></span><br><span class="line">a is main</span><br><span class="line">PID for parent before 2.sh:19028</span><br><span class="line">using fork</span><br><span class="line">PID FOR 2.SH:19029</span><br><span class="line">2.sh get a from main.sh is main</span><br><span class="line">now a is 2.sh</span><br><span class="line">PID FOR parent after 2.sh :19028</span><br><span class="line">now main.sh a is main</span><br></pre></td></tr></table></figure>

<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol>
<li><a href="http://qujunorz.blog.51cto.com/6378776/1541676" target="_blank" rel="noopener">http://qujunorz.blog.51cto.com/6378776/1541676</a></li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://wangxin201492.github.io/protocol/TOTP/protocol-TOTP-overview/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="wangxin201492">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="wangxin201492">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/protocol/TOTP/protocol-TOTP-overview/" itemprop="url">【一次性密码】TOTP</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2015-12-08T20:45:00+08:00">
                2015-12-08
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/protocol/" itemprop="url" rel="index">
                    <span itemprop="name">protocol</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/protocol/TOTP/" itemprop="url" rel="index">
                    <span itemprop="name">TOTP</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="1-OTP"><a href="#1-OTP" class="headerlink" title="1. OTP"></a>1. OTP</h2><p><code>OTP(One-Time Password)</code>译为一次性密码，也称动态口令。是使用密码技术实现的在客户端和服务器之间通过共享秘密的一种认证技术，是一种强认证技术，是增强目前静态口令认证的一种非常方便技术手段，是一种重要的双因素认证技术。</p>
<h3 id="1-1-OTP的认证原理"><a href="#1-1-OTP的认证原理" class="headerlink" title="1.1 OTP的认证原理"></a>1.1 OTP的认证原理</h3><p>动态口令的基本认证原理是在认证双方共享密钥，也称种子密钥，并使用的同一个种子密钥对某一个事件计数、或时间值、或者是异步挑战数进行密码算法计算，使用的算法有<code>对称算法</code>、<code>HASH</code>、<code>HMAC</code>，之后比较计算值是否一致进行认证。可以做到一次一个动态口令，使用后作废，口令长度通常为6-8个数字，使用方便，与通常的静态口令认证方式类似.</p>
<h3 id="1-3-OTP的实现方式"><a href="#1-3-OTP的实现方式" class="headerlink" title="1.3 OTP的实现方式"></a>1.3 OTP的实现方式</h3><ol>
<li>时间同步(<code>TOTP</code>)</li>
<li>事件同步(<code>HOTP</code>)</li>
<li>挑战/应答(<code>OCRA</code>)</li>
</ol>
<h2 id="2-HOTP"><a href="#2-HOTP" class="headerlink" title="2. HOTP"></a>2. HOTP</h2><p><code>HOTP(HMAC-base On-Time Password)</code>译为基于HMAC的一次性密码，也称事件同步的动态密码。</p>
<h3 id="2-1-HOTP的工作原理"><a href="#2-1-HOTP的工作原理" class="headerlink" title="2.1 HOTP的工作原理"></a>2.1 HOTP的工作原理</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HTOP(K,C) &#x3D; Truncate(HMAC-SHA-1(K,C))</span><br></pre></td></tr></table></figure>


<p>客户端和服务器事先协商好一个<code>密钥K</code>，用于一次性密码的生成过程。此外，客户端和服务器各有一个<code>计数器C</code>，并且事先将计数值同步。而<code>Truncate</code>是为了获得一个符合<code>HTOP</code>要求的值。</p>
<h2 id="3-TOTP"><a href="#3-TOTP" class="headerlink" title="3 TOTP"></a>3 TOTP</h2><p><code>TOTP(Time-base One-Time Password)</code>译为基于时间的一次性密码，也称时间同步的动态密码.</p>
<h3 id="3-1-TOTP的工作原理"><a href="#3-1-TOTP的工作原理" class="headerlink" title="3.1 TOTP的工作原理"></a>3.1 TOTP的工作原理</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">TOTP &#x3D; Truncate(HMAC-SHA-1(K,T))</span><br></pre></td></tr></table></figure>

<p><code>TOTP</code>是<code>HOTP</code>的一个变种，将<code>HOTP</code>中的<code>计数器C</code>替换为依托时间的<code>参数T</code>，T是由当前时间(<code>CurrentUnixTime</code>、初始时间(T0)、步长(X)决定的。即：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">T &#x3D; (Current Unix time - T0) &#x2F; X</span><br></pre></td></tr></table></figure>

<ul>
<li><code>CurrentUnixTime</code>：当前的Unix时间。</li>
<li><code>T0</code>： 开始计步初始化时间，默认为0</li>
<li><code>X</code> : 步长，默认情况下为30s</li>
</ul>
<h3 id="3-2-TOTP的要求"><a href="#3-2-TOTP的要求" class="headerlink" title="3.2 TOTP的要求"></a>3.2 TOTP的要求</h3><ol>
<li>客户端和服务器必须能够彼此知道或者推算出对方的Unix Time</li>
<li>客户端和服务器端必须共享一个密钥</li>
<li>算法必须使用HOTP作为其关键实现环节</li>
<li>客户端和服务器端必须使用相同的步长X</li>
<li>每一个客户端必须拥有不同的密钥</li>
<li>密钥的生成必须足够随机</li>
<li>密钥必须储存在防篡改的设备上，而且不能在不安全的情况下被访问或使用。</li>
<li>对该算法中T的实现必须大于<code>int32</code>，因为它在2038年将超出上限。</li>
<li>T0和X的协商必须在之前的步骤中就已经做好了。</li>
</ol>
<h3 id="3-3-安全性考虑"><a href="#3-3-安全性考虑" class="headerlink" title="3.3 安全性考虑"></a>3.3 安全性考虑</h3><h4 id="3-3-1-安全性分析"><a href="#3-3-1-安全性分析" class="headerlink" title="3.3.1 安全性分析"></a>3.3.1 安全性分析</h4><p>该算法的安全性和健壮性完全依赖于其关键实现环节<code>HOTP</code>。</p>
<p>安全性分析的结果是：在所有的测试中，该算法的结果均匀的、独立的分布。这个分析显示，最好的攻击和破解<code>TOTP(HOTP)</code>的方法是暴力破解。而在算法要求环节，要求key必须有足够的随机性。</p>
<h4 id="3-3-2-时延兼容"><a href="#3-3-2-时延兼容" class="headerlink" title="3.3.2 时延兼容"></a>3.3.2 时延兼容</h4><p>在同一个步长内，动态密码生成的结果是一样的。当一个验证系统获得这个动态密码的时候，它并不知道动态密码的生产者是在哪个步长内产生的密码。由于网络的原因，客户端生成密码的时间和服务器接受密码的时间可能差距会很大，很有可能使得这2个时间不在同一个步长内。当一个动态密码产生在一个步长的结尾，服务器收到的密码很有可能在下一个步长的开始。</p>
<p>验证系统应该设置一个策略允许动态密码的传输时延，不应该只验证当前步长的动态密码，还应该验证之前几个步长的动态密码。但越大的传输时延窗口设置，就会带来越大的风险被攻击，我们推荐最多设置一个时延窗口来兼容传输延时。</p>
<h4 id="3-3-3-步长设置"><a href="#3-3-3-步长设置" class="headerlink" title="3.3.3 步长设置"></a>3.3.3 步长设置</h4><p>步长大小的设置，直接影响安全性和可用性:</p>
<ol>
<li>一个越大的步长，就会导致一个越大的窗口被攻击。当一个动态密码被生成而且在其有效期内暴露在第三方环境下，那么第三方系统就可以在该动态密码无效前使用这个密码。</li>
<li>我们推荐默认的步长时间是<code>30s</code>，这个默认值是在权衡了安全性和可用性的基础上提出的。</li>
<li>下一个动态密码肯定会在下一个步长生成，用户必须等待当前步长的结束。这个等待时间的理想值会随着步长的设置而增大。一个太长的窗口设置不使用网络用户登录这种场景，用户可能等不了一个步长的时间，就放弃登录。</li>
</ol>
<blockquote>
<p>参考资料：<br><a href="http://blog.csdn.net/janronehoo/article/details/7590976" target="_blank" rel="noopener">http://blog.csdn.net/janronehoo/article/details/7590976</a><br><a href="http://www.dannysite.com/blog/165/" target="_blank" rel="noopener">http://www.dannysite.com/blog/165/</a><br><a href="https://tools.ietf.org/html/rfc6238" target="_blank" rel="noopener">https://tools.ietf.org/html/rfc6238</a></p>
</blockquote>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://wangxin201492.github.io/shell/shell-wait/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="wangxin201492">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="wangxin201492">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/shell/shell-wait/" itemprop="url">【shell】我的wait为什么不能用</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2015-10-18T20:01:48+08:00">
                2015-10-18
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/shell/" itemprop="url" rel="index">
                    <span itemprop="name">shell</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>希望实现这样的一个功能：主脚本会运行几个后台进程，并希望这几个后台进程运行完之后，主进程才会退出。</p>
<p>RT,设想一个文件a，希望a的每一行都表示一个后台进程，有如下内容：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ cat a</span><br><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td></tr></table></figure>

<h2 id="方式1"><a href="#方式1" class="headerlink" title="方式1"></a>方式1</h2><p>脚本<code>test_wait_1</code>这样写：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> filename:test_wait_1</span></span><br><span class="line"></span><br><span class="line">cat a | while read line</span><br><span class="line">do</span><br><span class="line">    echo $line &amp;</span><br><span class="line">done</span><br><span class="line">wait</span><br><span class="line">echo "wait done"</span><br></pre></td></tr></table></figure>

<p>运行结果：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#result</span><br><span class="line">$ bash test_wait_1</span><br><span class="line">1</span><br><span class="line">5</span><br><span class="line">3</span><br><span class="line">wait done</span><br><span class="line">4</span><br><span class="line">2</span><br></pre></td></tr></table></figure>

<p>显然，不尽如人意。</p>
<h2 id="方式2"><a href="#方式2" class="headerlink" title="方式2"></a>方式2</h2><p>脚本<code>test_wait_2</code>,做了一下修改：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> filename:test_wait_2</span></span><br><span class="line"></span><br><span class="line">while read line</span><br><span class="line">do</span><br><span class="line">    echo $line &amp;</span><br><span class="line">done &lt; "a"</span><br><span class="line">wait</span><br><span class="line">echo "wait done"</span><br></pre></td></tr></table></figure>

<p>运行结果：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ bash test_wait_2</span><br><span class="line">1</span><br><span class="line">2</span><br><span class="line">5</span><br><span class="line">4</span><br><span class="line">3</span><br><span class="line">wait done</span><br></pre></td></tr></table></figure>

<p>结果符合预期！！</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>维基百科中有这样一段话：</p>
<blockquote>
<p>其中n是当前正在执行的后台进程的pid，或工作的工作ID。如果没有给定n，命令会等待shell调用的所有工作终止。</p>
</blockquote>
<blockquote>
<p>wait一般返回最后一个工作的退出状态。如果n所指的工作不存在，或没有工作要等待，它会返回127。</p>
</blockquote>
<blockquote>
<p>因为wait需要知道当前shell执行环境的工作表，它通常为shell内建命令。</p>
</blockquote>
<p>这样看来仿佛<code>test_wait_1</code>中的用法也没有什么问题，但实际上shell的管道<code>|</code>实际上是产生了一级子shell，也就是在<code>test_wait_1</code>中的后台进程<code>echo $line &amp;</code>是主进程子shell的后台进程。而<code>wait</code>只会等待当前进程的后台进程执行完毕，所以<code>test_wait_1</code>在遇到wait语句直接退出了。</p>
<p>而<code>test_wait_2</code>中，通过<code>&lt; &quot;a&quot;</code>将a文件的内容标准输入到<code>while</code>中，并未通过管道输入到<code>while</code>中，所以后台进程属于主进程。wait会等待所有的后台进程完成以后退出，</p>
<p>这也就是<code>test_wait_1</code>和<code>test_wait_2</code>这2个脚本运行的不同之处。</p>
<h2 id="参考资料："><a href="#参考资料：" class="headerlink" title="参考资料："></a>参考资料：</h2><ul>
<li><p><a href="https://zh.wikipedia.org/wiki/Wait_(%E5%91%BD%E4%BB%A4)" target="_blank" rel="noopener">https://zh.wikipedia.org/wiki/Wait_(%E5%91%BD%E4%BB%A4)</a></p>
</li>
<li><p><a href="http://blog.csdn.net/shuanghujushi/article/details/38186303" target="_blank" rel="noopener">http://blog.csdn.net/shuanghujushi/article/details/38186303</a></p>
</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/">&lt;i class&#x3D;&quot;fa fa-angle-right&quot;&gt;&lt;&#x2F;i&gt;</a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">wangxin201492</p>
              <p class="site-description motion-element" itemprop="description">my blogs</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">13</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">14</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">21</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/wangxin201492" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:wangxin201492@sina.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">wangxin201492</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
